{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks examples to implement and apply speed up strategies to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Euclidean distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **[Euclidean distance matrix](https://en.wikipedia.org/wiki/Euclidean_distance_matrix)** is an $n \\times n$ matrix representing the spacing of a set of $n$ points in Euclidean space.\n",
    "For points $x_1,x_2,\\ldots,x_n$ in $k$-dimensional space $ℝ^k$, the elements of their Euclidean distance matrix $A$ are given by squares of distances between them.\n",
    "That is:\n",
    "\n",
    "<math>\\begin{align}\n",
    "A & = (a_{ij}); \\\\\n",
    "a_{ij} & = d_{ij}^2 \\;=\\; \\lVert x_i - x_j\\rVert^2,\n",
    "\\end{align}\n",
    "</math>\n",
    "\n",
    "where $\\|.\\|$ denotes the [Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm) on $ℝ^k$; in matrix notation:\n",
    "\n",
    "<math>\\begin{align}A = \\begin{bmatrix}\n",
    "0 & d_{12}^2 & d_{13}^2 & \\dots & d_{1n}^2 \\\\\n",
    "d_{21}^2 & 0 & d_{23}^2 & \\dots & d_{2n}^2 \\\\\n",
    "d_{31}^2 & d_{32}^2 & 0 & \\dots & d_{3n}^2 \\\\\n",
    "\\vdots&\\vdots & \\vdots & \\ddots&\\vdots&  \\\\\n",
    "d_{n1}^2 & d_{n2}^2 & d_{n3}^2 & \\dots & 0 \\\\\n",
    "\\end{bmatrix}\\end{align} </math>\n",
    "\n",
    "The task is to compute fast $A$, given a set of $n$ $k$-dimensional points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: run this cell twice\n",
    "%load euclidean_distance.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute $\\pi$ with Monte Carlo methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to generate $n$ random $(x, y)$ points in a $2D$ square of side length $2$, centered at the origin. Imagine a circle inscribed into the square, i.e. the unit circle. We then calculate the ratio of a number points that hit the circle $n_{\\text{inner}}$ and total number of generated points $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"img/monte_carlo_pi.png\" width=\"450px\"></td></tr>\n",
    "   <tr><td><center><sub>Source: <a href=\"https://www.kaggle.com/nickgould/monte-carlo-tutorial-calculating-pi/comments\">https://www.kaggle.com/nickgould/monte-carlo-tutorial-calculating-pi/comments</a></sub></center></td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a circle of radius $1$, enclosed by a $2 × 2$ square. The area of the circle is $\\pi r^2=\\pi$, the area of the square is $4$. If we divide the area of the circle, by the area of the square we get $\\frac{\\pi}{4}$. This is what the ratio of $n_{\\text{inner}}$ and $n$ approximates:\n",
    "\n",
    "\n",
    "<math>\\begin{align}\n",
    "\\frac{\\pi}{4} &\\approx \\frac{n_{\\text{inner}}}{n},\n",
    "\\end{align}\n",
    "</math>\n",
    "\n",
    "hence:\n",
    "\n",
    "<math>\\begin{align}\n",
    "\\pi &\\approx 4 \\cdot \\frac{n_{\\text{inner}}}{n}.\n",
    "\\end{align}\n",
    "</math>\n",
    "\n",
    "The task it to approximate value of $\\pi$ using the above hit-or-miss method in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: run this cell twice\n",
    "%load pi.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a grid search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model **hyperparameter** in machine learning is a parameter that describes how model learns and not what it learns from data. The value of the hyperparameter has to be chosen before the learning process begins.\n",
    "\n",
    "**[Hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization)** or hyperparamter tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm.\n",
    "\n",
    "The traditional way of performing hyperparameter optimization has been **grid search**, or a parameter sweep. It is simply an exhaustive searching through a manually specified grid of points in the hyperparameter space of a learning algorithm. A grid search algorithm must be guided by some performance metric, typically measured by cross-validation on the training set or evaluation on a held-out validation set.\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"img/Hyperparameter_Optimization_using_Grid_Search-800px-wikidpedia_de.png\" width=\"600px\"></td></tr>\n",
    "   <tr><td><center><sub>Source: <a href=\"https://de.wikipedia.org/wiki/Hyperparameteroptimierung\">https://de.wikipedia.org/wiki/Hyperparameteroptimierung</a></sub></center></td></tr>\n",
    "</table>\n",
    "\n",
    "Since the parameter of a machine learner may have unbounded real or integer values for certain parameters, one might need to manually set bounding box of the search. Furthermore, in case of continuous real parameter values one needs to discretize the corresponding subspace to form a grid. The grid points customarily are equally spaced, but do not need to be.\n",
    "\n",
    "The task is to run a grid search in parallel given data, a machine learning model, and specification of model hyperparameters search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: run this cell twice\n",
    "%load grid_search.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count words\n",
    "\n",
    "In the fields of natural language processing (NLP) a text or a speech is often represented by counts of words in it. For instance, a text:\n",
    "```\n",
    "to be or not to be\n",
    "```\n",
    "gives the following word counts representation:\n",
    "```\n",
    "to:  2\n",
    "be:  2\n",
    "or:  1\n",
    "not: 1\n",
    "```\n",
    "\n",
    "The task is to count words in a given text file and sort them from the most common to the least common word.\n",
    "\n",
    "<p style=\"font-size: smaller;\"> \n",
    "    Counting words is a special case of counting <a href=\"https://en.wikipedia.org/wiki/N-gram\">n-grams</a>, i.e. a contiguous sequence of n items from a given sample of text or speech; for instance, <em>be or not</em> is a 3-gram. Words are unigrams (1-grams), whereas in texts with a high frequency words like <em>to</em> or <em>not</em>, mixed with a low frequency words like <em>discombobulate</em>, it is usually better to use bi-, tri- or even higher order n-grams.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: run this cell twice\n",
    "%load counting_words.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
