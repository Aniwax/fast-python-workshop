{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE THIS CELL WHICH CUSTOMIZES LAYOUT AND STYLING OF THE NOTEBOOK !\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings = lambda *a, **kw: None\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(open(\"../documents/custom.html\", \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<span style=\"background:#f0f0e0;padding:1em\">Copyright (c) 2020-2021 ETH Zurich, Scientific IT Services. This work is licensed under <a href=\"https://creativecommons.org/licenses/by-nc/4.0/\">CC BY-NC 4.0</a></span><br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 2.5em; font-weight: bold;\">Section 7: Graphics Processing Units (GPUs)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 30%; text-align:center\">\n",
    "            <figure>\n",
    "                <div style=\"overflow:hidden; display:inline-block;\">\n",
    "               <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/AMD%4014nm%40GCN_5th_gen%40Vega10%40Radeon_RX_Vega_64%40ES-Sample%40_Stack-DSC09254-DSC09287_-_ZS-retouched.jpg/1280px-AMD%4014nm%40GCN_5th_gen%40Vega10%40Radeon_RX_Vega_64%40ES-Sample%40_Stack-DSC09254-DSC09287_-_ZS-retouched.jpg\">\n",
    "                </div>\n",
    "               <figcaption style=\"text-align: center\">\n",
    "                   <a href=\"https://commons.wikimedia.org/wiki/File:AMD@14nm@GCN_5th_gen@Vega10@Radeon_RX_Vega_64@ES-Sample@_Stack-DSC09254-DSC09287_-_ZS-retouched.jpg\">\n",
    "                       Wikimedia.org\n",
    "                   </a>\n",
    "                   :\n",
    "                   <a href=\"https://creativecommons.org/publicdomain/zero/1.0/deed.en\">\n",
    "                       CC0 1.0\n",
    "                   </a>\n",
    "               </figcaption>\n",
    "            </figure>\n",
    "        </td>\n",
    "        <td style=\"width: 70%; text-align: left; font-size: 1.2em; line-height:160%;\">\n",
    "            \n",
    "Graphics Processing Units (GPUs) were initially designed to do just that: <b>process graphics</b>. \n",
    "            \n",
    "As demands grew, an increasing number of tasks was moved onto the GPU, and developers needed more and more control over the graphics pipeline. Of course, one of the main drivers behind the development of both hardware and the ecosystem was <a href=https://en.wikipedia.org/wiki/DirectX>gaming</a>, but also engineering and cinematic applications <a href=\"https://www.pearson.com/us/higher-education/program/Sanders-CUDA-by-Example-An-Introduction-to-General-Purpose-GPU-Programming/PGM200291.html\">played an important role</a>.            \n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History\n",
    "\n",
    "The field standardized around graphics APIs like [OpenGL](https://en.wikipedia.org/wiki/OpenGL) or [DirectX]() that permit developers to control the graphics that are rendered onto the monitor, and those were continuously expanded. An important milestone was reached when DirectX 8.0, released in the year 2000, [gave developers more direct control over the shaders that are executed on the GPU](https://www.pearson.com/us/higher-education/program/Sanders-CUDA-by-Example-An-Introduction-to-General-Purpose-GPU-Programming/PGM200291.html).\n",
    "\n",
    "## Pioneers\n",
    "\n",
    "This sparked the interest of researchers who started to \"<b>misuse</b>\" the capability for computations. In the beginning, this was an inconvenient task: GPU programming still required a use of graphics APIs like the ones mentioned above, and data input and output needed to be done using graphics primitives like pixel colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Faster The Better\n",
    "\n",
    "Traditional strategies that increase the performance of applications like boosting clock speeds have [hit limits](http://www.gotw.ca/publications/concurrency-ddj.htm) (\"the free lunch is over\", see Section 1).\n",
    "As was discussed in the previous sections, writing software that takes advantage of current state-of-the art CPUs like AMD's 64 core processor [available at the ETH HPC Euler cluster](https://scicomp.ethz.ch/wiki/Euler) means exploiting parallelism. This is particularly true for GPUs.\n",
    "\n",
    "<br/>\n",
    "<figure>\n",
    "   <img src=\"https://scicomp.ethz.ch/w/images/7/76/ETH_Zurich_Euler_II_and_I_in_LCA.jpg\" style=\"max-width: 600px\"/>\n",
    "       <figcaption style=\"text-align: center\">\n",
    "           <a href=\"https://scicomp.ethz.ch/wiki/File:ETH_Zurich_Euler_II_and_I_in_LCA.jpg\">\n",
    "               scicomp.ethz.ch\n",
    "           </a>\n",
    "           :\n",
    "           © 2015 Olivier Byrde, ETH Zurich\n",
    "       </figcaption>\n",
    "</figure>\n",
    "\n",
    "## Cores\n",
    "\n",
    "Drawing from their heritage in computer graphics, GPUs have been designed to tackle [highly parallelizable workloads](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units). This also shows in <b>core count</b>. For instance, Nvidia's recently released A100 GPU provides around [7000 CUDA cores](https://en.wikipedia.org/wiki/Ampere_(microarchitecture)). If exploited by an application, this permits a speed-up of up to [around an order of magnitude](https://www.karlrupp.net/2016/08/flops-per-cycle-for-cpus-gpus-and-xeon-phis/#more-676).\n",
    "\n",
    "## Performance\n",
    "\n",
    "Of course, the actual performance increase depends on the concrete hardware and the application. GPUs will not replace CPUs anytime soon, but offloading work to this coprocessor has the additional advantage of freeing up CPU resources for other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "Deep learning has been able to improve the performance of computers in many interesting fields of application. However, working with neural networks often requires significant computational resources. Very often, some of the necessary compute power is provided by GPUs. For instance, versions of [AlphaGo used up to 280 GPUs and thousands of CPUs](https://en.wikipedia.org/wiki/AlphaGo).\n",
    "\n",
    "<figure>\n",
    "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png\" style=\"max-width: 600px\"/>\n",
    "       <figcaption style=\"text-align: center\">\n",
    "           <a href=\"https://commons.wikimedia.org/wiki/File:MultiLayerNeuralNetworkBigger_english.png\">\n",
    "               Wikimedia.org\n",
    "           </a>\n",
    "           :\n",
    "           <a href=\"https://creativecommons.org/licenses/by-sa/3.0/deed.en\">\n",
    "               CC BY-SA 3.0\n",
    "           </a>\n",
    "       </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU versus GPU\n",
    "\n",
    "CPUs and GPUs are designed for different purposes and the architects have therefore made different tradeoffs. We'll try to explain those use cases with an analog in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU: The Racing Car\n",
    "\n",
    "Let's say you live in Zurich and you want to go skiing in Laax, which is about 80 kilometers from Zurich. Environmental concerns aside, which mode of transportation would you choose?\n",
    "\n",
    "Most likely, you would choose the car.\n",
    "\n",
    "<figure>\n",
    "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9a/Bugatti_Chiron_%2823628630038%29.jpg\" style=\"max-width: 600px\"/>\n",
    "       <figcaption style=\"text-align: center\">\n",
    "           <a href=\"https://commons.wikimedia.org/wiki/File:Bugatti_Chiron_(23628630038).jpg\">\n",
    "               Wikimedia.org\n",
    "           </a>\n",
    "           :\n",
    "           <a href=\"https://creativecommons.org/licenses/by/2.0/deed.en\">\n",
    "               CC BY 2.0\n",
    "           </a>\n",
    "       </figcaption>\n",
    "</figure>\n",
    "\n",
    "The reason is that it is designed for this type of use:\n",
    "\n",
    "* Fast\n",
    "* Multipurpose\n",
    "* Large storage space per person\n",
    "\n",
    "In this sense the car is like the CPU:\n",
    "\n",
    "* High clock speed\n",
    "* Most applications work\n",
    "* Large main memory per core\n",
    "\n",
    "CPUs are great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU: The Bus\n",
    "However, what if you want to go together with your local skiing club? In this case, using the car is very inconvenient. It is still the fastest way to go to Laax once, but you'll have to drive back and forth to transport everybody. If you have access to one, you would likely choose to go by bus instead.\n",
    "\n",
    "<figure>\n",
    "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/e0/Van-Hool-Bus_in_München.jpg\" style=\"max-width: 600px\"/>\n",
    "       <figcaption style=\"text-align: center\">\n",
    "           <a href=\"https://commons.wikimedia.org/wiki/File:Van-Hool-Bus_in_München.jpg\">\n",
    "               Wikimedia.org\n",
    "           </a>\n",
    "           :\n",
    "           <a href=\"https://creativecommons.org/licenses/by/3.0/de/deed.en\">\n",
    "               CC BY 3.0 DE\n",
    "           </a>\n",
    "       </figcaption>\n",
    "</figure>\n",
    "\n",
    "Of course, a bus is designed for this type of use:\n",
    "\n",
    "* Transports a group at once\n",
    "* Car can be used for something else\n",
    "\n",
    "Note that this is true even if the bus is slower than the car, the group has to be at the stop at the same time, the group has to walk to the stop, and there's less storage space per person.\n",
    "\n",
    "Again, this example translates to properties of a GPU:\n",
    "\n",
    "* Many cores\n",
    "* Work can be offloaded from the CPU to the GPU\n",
    "* Lower clock speed than the CPU\n",
    "* Many similar tasks should be available at the same time\n",
    "* Memory needs to be transferred to the GPU\n",
    "* Smaller GPU memory\n",
    "\n",
    "GPUs are great, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU: Use Cases\n",
    "\n",
    "Based on these properties, there are some workloads that are particularly suitable for the GPU. In fact, GPUs have been used in a [wide field of applications](https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units).\n",
    "\n",
    "* Neural Networks, machine learning\n",
    "* Video processing, computer vision\n",
    "* Scientific computing (climate research, molecular dynamics, ...)\n",
    "* ...\n",
    "\n",
    "However, applications need to respect the different programming model on GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMT Programming Model\n",
    "\n",
    "Many CPUs provide SIMD ([single instruction multiple data](https://en.wikipedia.org/wiki/SIMD)) instructions that permit the developer (or compiler) to perform the same operation on a batch of data to improve performance. GPUs usually take a different approach. This model is called SIMT: [single instruction multiple threads](https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads). \n",
    "\n",
    "In this model developers control [individual threads](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture). To get a first impression of that concept, let's consider a function that adds some numbers in a list `source` to a list `target`. In Python, this function could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to(source, target):\n",
    "    \"\"\"Adds the elements of `source` to the elements of `target` at the same index.\"\"\"\n",
    "    for index in range(len(source)):\n",
    "        target[index] += source[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the SIMD world, we would make sure that [chunks of the addition operations are performed in parallel](https://yosefk.com/blog/simd-simt-smt-parallelism-in-nvidia-gpus.html). On the other hand, in the SIMT programming model, we specify the work of a single thread (pseudo-code, we will see a complete example later). This function also produces the expected result if we have `len(source)` threads and each of them calls the function. However, since many of us are more used to loops, low-level GPU programming can take some getting used to.\n",
    "\n",
    "$$ \\textrm{target} = \\begin{pmatrix} [\\textrm{computed by thread$_0$ using source$_0$}] \\\\ \\vdots \\\\ [\\textrm{computed by thread$_n$ using source$_n$}] \\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_simt(source, target):\n",
    "    \"\"\"Adds the element of `source` at `thread_index` to the element of `target` at the same index.\"\"\"\n",
    "    target[thread_index] += source[thread_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the SIMT programming model gives a lot of control to the developer. However, applications will only perform well if [the threads move in lockstep](https://hdms.bsz-bw.de/frontdoor/deliver/index/docId/4500/file/gpgpu-origins-and-gpu-hardware-architecture.pdf). Performance is [suboptimal if the threads diverge](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture) (i.e. execute different branches), which is why domain decomposition (in the sense of performing the same operation on a chunk of data in every thread) is usually a promising approach. In particular, if-statements (branches) on GPUs are [problematic](https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Vendors, Different Platforms\n",
    "\n",
    "Moreover, the current GPU market differs from the CPU market considerably. When programming for CPUs, and especially when using Python, a program written for a desktop Intel CPU will (usually) also work on a desktop AMD CPU. Unfortunately, the GPU market has not converged to this extent.\n",
    "\n",
    "There are [three main vendors of GPUs](https://www.statista.com/statistics/754557/worldwide-gpu-shipments-market-share-by-vendor/). Each of these vendors pushes their own platform for GPU programming (including compilers):\n",
    "\n",
    "* Intel: [oneAPI](https://www.oneapi.com)\n",
    "* Nvidia: [CUDA](https://en.wikipedia.org/wiki/CUDA)\n",
    "* AMD: [ROCm](https://www.amd.com/de/graphics/servers-solutions-rocm)\n",
    "\n",
    "This makes porting code between vendors challenging, even if there are (limited) ways to accomplish this (e.g. [OpenCL](https://de.wikipedia.org/wiki/OpenCL)).\n",
    "\n",
    "Fortunately, higher level packages exist in the Python ecosystem. These packages (e.g. [TensorFlow](https://www.tensorflow.org), [PyTorch](https://pytorch.org), [Numba](https://numba.pydata.org), ...) support different computational platforms and therefore allow the user to work on system-independent code.\n",
    "\n",
    "Since only Nvidia/CUDA cards are available in the [Euler cluster](https://scicomp.ethz.ch/wiki/Getting_started_with_GPUs), we will focus on this platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-accelerated Python Libraries\n",
    "\n",
    "Python programmers can directly access the Nvidia CUDA and CUDA toolkit APIs with:\n",
    "* [PyCUDA](https://documen.tician.de/pycuda/) to access Nvidia CUDA's parallel computing API.\n",
    "* [Scikit-CUDA](https://scikit-cuda.readthedocs.io/en/latest/) to access the Nvidia CUDA programming toolkit libraries including CUBLAS, CUFFT and CUSOLVER.\n",
    "* [CUDA Python](https://developer.nvidia.com/cuda-python)\n",
    "\n",
    "Fortunately, there are also many Python libraries that offer convenient ways to perform mathematical operations on the GPU. For instance, we've already mentioned [TensorFlow](https://www.tensorflow.org/) and [PyTorch](https://pytorch.org/) which allow creating deep learning models in Python and perform training on the GPU. There are also general purpose GPU-accelerated Python libraries which often mimmick the API of well-known Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAPIDS\n",
    "\n",
    "[RAPIDS](https://www.rapids.ai) is a data science framework ([incubated by Nvidia](https://rapids.ai/about.html)) which offers GPU-accelerated libraries for executing end-to-end data science pipelines, from data preparation to machine learning. The libraries available in the RAPIDS framework include:\n",
    "\n",
    "* cuDF: a dataframe manipulation library that mimmicks [pandas](https://pandas.pydata.org)\n",
    "* cuML: a collection of machine learning libraries similar to [scikit-Learn](https://scikit-learn.org/stable/)\n",
    "* cuSignal: a direct port of [SciPy](https://scipy.org) Signal to the GPU\n",
    "* cuGraph: a collection of graph algorithms that matches the API of [NetworkX](https://networkx.org)\n",
    "\n",
    "RAPIDS is available as a Conda package or as a Docker image, but it can also be built from source. It integrates well with other open source projects such as [Apache Arrow](https://arrow.apache.org), [Dask](https://dask.org), [XGBoost](https://xgboost.ai), [scikit-Learn](https://scikit-learn.org/stable/) to provide a GPU-accelerated data science ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CuPy\n",
    "\n",
    "[CuPy](https://cupy.dev) is [developed by Preferred Networks](https://cupy.dev/) and provides a feature set similar to NumPy on Nvidia GPUs. We'll have a closer look at how CuPy can be used to port an algorithm to the GPU in the demo section below.\n",
    "\n",
    "CuPy has the following hardware and software requirements (see the [documentation](https://docs.cupy.dev/en/stable/install.html#install-cupy) for details)\n",
    "\n",
    "* Nvidia CUDA GPU\n",
    "* Nvidia CUDA Toolkit\n",
    "* Python3\n",
    "\n",
    "You can install CuPy using `pip install cupy-cuda<version>`; see the [CuPy documentation](https://docs.cupy.dev/en/stable/install.html#installing-cupy) for more details.\n",
    "\n",
    "Note that, in particular, Euler satisfies the requirements above, and CuPy is already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demos\n",
    "\n",
    "In this section we will first look at two examples that show how to create custom GPU-accelerated Python scripts. The first example uses CuPy as a drop-in replacement as this is the easiest way to use a GPU with Python. We will already see a performance gain; however, we are restricted by the functions provided by the library. The second example shows how you can gain more flexibility and control by using Numba for CUDA. Finally we will look at training a TensorFlow model.\n",
    "\n",
    "Before showing the demo, we would like to explain how to request a GPU node on the Euler cluster, load modules and run Jupyter on the cluster. Please note that only the members of shareholder groups have access to GPUs on the cluster.\n",
    "\n",
    "**Request a GPU node on the cluster**\n",
    "\n",
    "When you have logged in to the cluster, you can request 1 GPU node by using the `bsub` option `-R \"rusage[ngpus_excl_p=1]\"`. Here is a command example to request an interactive session on a compute node with 1 GPU:\n",
    "\n",
    "```bash\n",
    "$ bsub -n 4 -W 01:00 -R \"rusage[mem=2048, ngpus_excl_p=1]\" -Is bash\n",
    "```\n",
    "\n",
    "**Load Python module for GPU**\n",
    "\n",
    "The `python_gpu` module on the cluster includes TensorFlow and CuPy. By loading this Python module, the CUDA toolkit, the CuDNN and the NCCL library are also made available. The loading command reads:\n",
    "\n",
    "```bash\n",
    "$ module load gcc/6.3.0 python_gpu/3.8.5\n",
    "```\n",
    "\n",
    "**Run Jupyter on the cluster**\n",
    "\n",
    "From your local computer, you can start a Jupyter Notebook in a batch job on the cluster with GPUs by using the script [provided by cluster support](https://gitlab.ethz.ch/sfux/Jupyter-on-Euler-or-Leonhard-Open). To run this script, follow the instructions in the README of the linked repository for the initial setup. Then use a command similar to the following example (replacing \"\\<USERNAME>\" by your ETH username):\n",
    "\n",
    "```bash\n",
    "$ ./start_jupyter_nb.sh --username <USERNAME> --numgpu 1 --numcores 4 --memory 2048 --extra-modules gcc/6.3.0 --extra-modules python_gpu/3.8.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-23T22:45:39.709976Z",
     "iopub.status.busy": "2020-10-23T22:45:39.708814Z",
     "iopub.status.idle": "2020-10-23T22:45:39.719418Z",
     "shell.execute_reply": "2020-10-23T22:45:39.717723Z",
     "shell.execute_reply.started": "2020-10-23T22:45:39.709714Z"
    }
   },
   "source": [
    "## Demo: CuPy\n",
    "\n",
    "For this example we use the NumPy version of the Euclidean distance matrix example as a starting point. We will replace NumPy with CuPy to offload calculations to the GPU. \n",
    "\n",
    "Let's recall the NumPy version before we move on to the CuPy version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numpy version**\n",
    "\n",
    "We use NumPy for the setup and focus using CuPy in the calculation of a distance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def create_random_points(number_of_points: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Returns number_of_points random points in 3D space.\n",
    "    \"\"\"\n",
    "    return np.random.rand(number_of_points, 3)\n",
    "\n",
    "\n",
    "random_points = create_random_points(4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we use `%timeit` to measure the runtime of the NumPy version to compare with that of the CuPy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat demos/demo_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demos.demo_numpy import distance_matrix as distance_matrix_numpy\n",
    "\n",
    "%timeit distance_matrix_numpy(random_points)\n",
    "M = distance_matrix_numpy(random_points)\n",
    "print(M[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CuPy version**\n",
    "\n",
    "First, import cupy. Note that `cp` is a widely used abbreviation for `cupy`, just as `np` is for `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cupy as cp\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start manipulating arrays and calculating on the GPU, we create an array on the current GPU device by using the command `cp.array`. CuPy makes using GPUs simple by mimicking NumPy functions, so we can directly replace `np.einsum` with `cp.einsum` and `np.matmul` with `cp.matmul`. After the calculation on the GPU, we return an array to the host memory by using the command `cp.asnumpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pycat demos/demo_cupy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from demos.demo_cupy import distance_matrix as distance_matrix_cupy\n",
    "\n",
    "    %timeit distance_matrix_cupy(random_points)\n",
    "    M = distance_matrix_cupy(random_points)\n",
    "    print(M[:5, :5])\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the time measurement, with very little effort, we have sped up the computation by around 4 times for `n=4096`! Also, we still get the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the Numpy to the GPU version\n",
    "Does the GPU always perform better in this example? Let's take a closer look at the special case where the problem size is small (number of points less than 800). To do so, we have created a benchmark you can find in the subdirectory `demos/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"demos/measurements.json\") as measurements_file:\n",
    "    measurements = json.load(measurements_file)\n",
    "\n",
    "for label in [\"numpy\", \"cupy\"]:\n",
    "    transform = {\"numpy\": \"numpy (1 core)\", \"cupy\": \"cupy\"}\n",
    "    plt.plot(\n",
    "        [int(key) for key in measurements.keys()],\n",
    "        [value[label] for value in measurements.values()],\n",
    "        label=transform[label],\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Average runtime [s]\")\n",
    "plt.title(\"Comparison of NUMPY versus CUPY implementations\")\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0.0, 0.002)\n",
    "plt.xlim(10, 800);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that, for a number of points not large enough, the CPU is faster than GPU!\n",
    "\n",
    "We used `line_profiler` to check which function causes this behavior. As `line_profiler` is not provided in the centrally-installed Python packages on the cluster, it can be installed locally in the home directory on the cluster with the command `pip install --user line-profiler` (or alternatively in a [virtual environment](https://docs.python.org/3/library/venv.html)). Please see Section 2 for how to use `line_profiler` and how to interpret the output.\n",
    "\n",
    "The command line to profile the numpy and cupy versions of the function reads:\n",
    "```bash\n",
    "$ kernprof -vl benchmark_cupy.py 10\n",
    "```\n",
    "\n",
    "where 10 is the number of points in the array. In this test, we varied the number of points from 10 to 800.\n",
    "\n",
    "In the following, \"ops\" refers to the line that computes `x_2 - 2 * x_y + y_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"demos/measurements_ops.json\") as measurements_file:\n",
    "    measurements = json.load(measurements_file)\n",
    "\n",
    "number_of_points = [int(key) for key in measurements.keys()]\n",
    "\n",
    "for library, style in zip([\"np\", \"cp\"], [\"--\", \"-\"]):\n",
    "    for tag in [\"einsum\", \"matmul\", \"ops\"]:\n",
    "        label = f\"{library}.{tag}\"\n",
    "        plt.plot(\n",
    "            number_of_points,\n",
    "            [value[label] for value in measurements.values()],\n",
    "            style,\n",
    "            label=label,\n",
    "        )\n",
    "\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Average runtime [microseconds]\")\n",
    "plt.title(\"Comparison of NUMPY versus CUPY operations\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(10, 800);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the comparison of the runtimes between the NumPy and the CuPy operations, the CPU computed the smaller tasks faster than the GPU. However, when the problem size increased, the runtime of NumPy operations (such as `np.matmul`, multiplication, and addition) increased steeply with the problem size. On the other hand, GPU (lower clock speed, highly parallel) was slower for the small problem sizes but the runtime stayed almost the same as the problem size increased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU memory limit**\n",
    "\n",
    "The GPU is fast but a limitation of the GPU is the memory size. When running the CuPy version with `n=30^3` in this notebook the peak memory consumption of the function `distance_matrix` was around 16 GB. This exceeded the available memory size of the GPU we used (NVIDIA GeForce RTX 2080 Ti, 11GB). Therefore, for larger problems, we would need to use the CPU or break up a dataset into chunks so that each chunk can fit into the GPU memory and adapt the algorithm to process data chunk-wise on the GPU (see Outlook below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Numba for CUDA\n",
    "\n",
    "While using drop-in replacement libraries is the way to go wherever this is feasible, this approach is limited to the algorithms and building blocks provided by these libraries. We need to dive a bit deeper if more flexibility or control is required.\n",
    "\n",
    "As was already discussed in previous sections of this course, Numba can be used to compile a subset of Python to machine code. Sometimes, adding a Numba annotation is enough to improve the performance considerably. Fortunately, Numba can also compile code for GPUs. In fact, Numba supports both [CUDA and ROCm](https://numba.pydata.org/numba-doc/dev/cuda/index.html). In the following we will focus on CUDA.\n",
    "\n",
    "Let's try to reproduce the previous example, i.e. compute the Euclidean distance matrix, using Numba for CUDA. Unfortunately, Numba for CUDA does not support many useful features. For instance, the following standard Python features are [missing](https://numba.pydata.org/numba-doc/dev/cuda/cudapysupported.html) as of early 2021:\n",
    "\n",
    "* Exception handling\n",
    "* Comprehensions\n",
    "* Generators\n",
    "\n",
    "For our use case it's important to note that Numpy arrays are in fact supported, but only with a subset of features. We can use Numpy arrays to transfer data.\n",
    "\n",
    "Here's a possible first implementation of the Euclidean distance matrix algorithm for GPUs. Following the programming model required by CUDA (see the section on SIMT above), the idea is to write code that computes a single entry of the final matrix. Recall that this entry contains the squared distance between two points.\n",
    "\n",
    "$$ \\textrm{distance_matrix} = \\begin{pmatrix} [\\textrm{computed by thread$_{0,0}$}] & \\dots & [\\textrm{computed by thread$_{0, n}$}] \\\\ \\vdots & \\vdots & \\vdots \\\\ [\\textrm{computed by thread$_{n, 0}$}] & \\dots & [\\textrm{computed by thread$_{n, n}$}]\\end{pmatrix} $$\n",
    "\n",
    "The formula for each entry depends on its (row, column)-coordinates, which we obtain from the location of executing thread in the \"CUDA grid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycat demos/demo_numba_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've added a `cuda.jit` decorator to request CUDA compilation. \n",
    "\n",
    "Say we have `number_of_points` points that we want to compute the Euclidean distance matrix for. Note that the `distance_matrix_gpu` function obtains the row and the column that it is working on from the location of its executing thread in the \"CUDA grid\". Therefore we'll launch a two-dimensional square grid of size `number_of_points * number_of_points`. This can be done when invoking the function (commonly called \"kernel\").\n",
    "\n",
    "For instance, we could invoke it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demos.demo_numba_gpu import distance_matrix as distance_matrix_numba_gpu\n",
    "\n",
    "try:\n",
    "    number_of_points = random_points.shape[0]\n",
    "    result = np.zeros((number_of_points, number_of_points))\n",
    "    distance_matrix_numba_gpu[(number_of_points, number_of_points), (1, 1)](\n",
    "        random_points, result\n",
    "    )\n",
    "    print(result[:5, :5])\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the code snippet requires CUDA to run. However, debugging on a CPU is possible by setting the [environment variable `NUMBA_ENABLE_CUDASIM=1`](https://numba.pydata.org/numba-doc/dev/cuda/simulator.html).\n",
    "\n",
    "\n",
    "The most important take away here is that Numba for CUDA can be used to implement arbitrary algorithms that run on GPUs. However, keep in mind that GPU programming is challenging, and that drop-in replacements often provide better performance. In fact, there are many aspects that can be improved in our algorithm. For instance, we are recomputing `result[col][row]` which we already know because it's the same as `result[row][col]`. Also, the hardware architecture of GPUs comes with a complex memory hierarchy (e.g. shared memory) that we are ignoring at the moment. This is beyond the scope of this introduction, but the [CUDA C Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/) provides more information if you are interested.\n",
    "\n",
    "To conclude this section we look at a benchmark of the above algorithm on the cluster. For scale, we are comparing against a sequential (i.e. single-threaded) Numba implementation running on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"demos/measurements.json\") as measurements_file:\n",
    "    measurements = json.load(measurements_file)\n",
    "\n",
    "for label in [\"cpu\", \"gpu\", \"numpy\", \"cupy\"]:\n",
    "    transform = {\n",
    "        \"cpu\": \"numba-cpu (1 core)\",\n",
    "        \"gpu\": \"numba-gpu\",\n",
    "        \"numpy\": \"numpy (1 core)\",\n",
    "        \"cupy\": \"cupy\",\n",
    "    }\n",
    "    plt.plot(\n",
    "        [int(key) for key in measurements.keys()],\n",
    "        [value[label] for value in measurements.values()],\n",
    "        label=transform[label],\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Number of points\")\n",
    "plt.ylabel(\"Average runtime [s]\")\n",
    "plt.title(\"Comparison of Numba Targets\")\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0.0, 0.005)\n",
    "plt.xlim(10, 800);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a sufficiently large number of points, the `cupy` based solution outperforms the other solutions. However, `numba` can be used to to implement algorithms not directly supported by `cupy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Training a TensorFlow model on the cluster\n",
    "\n",
    "To round off our overview of using GPUs to power Python applications we'll have a look at the optimal case where there exists an established GPU-enabled Python package to perform the desired computations.\n",
    "More precisely, we'll look at the common use case of traininig a TensorFlow model.\n",
    "\n",
    "As mentioned before, the `python_gpu` module comes with TensorFlow and neccessary libraries included. Here is the module load command again:\n",
    "\n",
    "```bash\n",
    "$ module load gcc/6.3.0 python_gpu/3.8.5\n",
    "```\n",
    "\n",
    "Now we can try to import the TensorFlow package in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try it out, we have used an [official TensorFlow example](https://www.tensorflow.org/tutorials/images/cnn) of convolutional neural network training on the [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset on an AMD EPYC 7742, and a RTX 2080 Ti. The CIFAR10 dataset consists of 60,000 images which were split into 50,000 training images and 10,000 test images. The batch size was fixed to 32 and the number of epochs was 10 which gave a test accuracy of 70%. The performance results were averaged over 10 experiments on each system and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"demos/measurements_tf_cnn_cifar10.json\") as measurements_file:\n",
    "    measurements = json.load(measurements_file)\n",
    "\n",
    "for value in measurements.values():\n",
    "    devices = [device for device in value.keys()]\n",
    "    speed = [value[device] for device in devices]\n",
    "\n",
    "plt.barh(devices, speed)\n",
    "plt.title(\"Training CNN on CIFAR10 dataset\")\n",
    "plt.xlabel(\"Training speed [images/sec]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a convolutional neural network (CNN) model, the inputs of each convolutional layer are multiplied by its weight. These are simple tasks but a CNN model can have a large number of parameters. In this example, the CNN model has a total of 122,570 parameters. To perform multiplication operations one after another on a single CPU is very time consuming, and therefore, performing these tasks in parallel accelerates the computation. For the training dataset of 50,000 images, the EPYC 7742 CPU took 9.4 minutes on a single thread to train on the images and 1.7 minutes on 32 threads. An Nvidia GPU RTX 2080 Ti, which has 4352 Nvidia CUDA cores, took only 1 minute to solve the same problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Outlook\n",
    "\n",
    "The compute resources available to a single GPU, i.e. cores and memory, are not infinite. Multi-GPU setups make it possible to run even larger scale computations. There are basically two ways to use more than one GPU at once:\n",
    "\n",
    "* A single process acesses more than one GPU.\n",
    "* Multiple processes use GPUs.\n",
    "\n",
    "The former can be achieved using technology like [NVLink](https://www.nvidia.com/de-de/design-visualization/nvlink-bridges/) and [NCCL](https://developer.nvidia.com/nccl). The latter solution can be implemented using [MPI](https://www.mpi-forum.org) and e.g. domain decomposition (see Section 5).\n",
    "\n",
    "If you don't need control over the details, there higher level packages that can help with simplifying the process. Some are designed for a specific use case (e.g. [TensorFlow](https://www.tensorflow.org) has [multi-GPU support](https://www.tensorflow.org/guide/gpu)), but there are also more general libraries and frameworks. For instance, [Dask](https://dask.org) has [multi-GPU support](https://docs.dask.org/en/latest/gpu.html). There's also a promising library by Nvidia ([Legate](https://developer.nvidia.com/legate-early-access)) in the works.\n",
    "\n",
    "... So you might actually rent an entire fleet of double-decker buses to go skiing.\n",
    "\n",
    "<figure>\n",
    "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/49/Line-up_of_RT_buses_inside_Barking_bus_garage_%28geograph_6106538%29.jpg\" style=\"max-width: 600px\"/>\n",
    "   <figcaption style=\"text-align: center\">\n",
    "       <a href=\"https://commons.wikimedia.org/wiki/File:Line-up_of_RT_buses_inside_Barking_bus_garage_(geograph_6106538).jpg\">\n",
    "           Wikimedia.org\n",
    "       </a>\n",
    "       :\n",
    "       <a href=\"https://creativecommons.org/licenses/by-sa/2.0/deed.en\">\n",
    "           CC BY-SA 2.0\n",
    "       </a>\n",
    "   </figcaption>\n",
    "</figure>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
