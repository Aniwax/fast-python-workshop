{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# IGNORE THIS CELL WHICH CUSTOMIZES LAYOUT AND STYLING OF THE NOTEBOOK !\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings = lambda *a, **kw: None\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(open(\"custom.html\", \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"font-size: 2.5em; font-weight: bold;\">Section 4: Optimization</p>\n",
    "\n",
    "In this section we will introduce important libraries and  tools speed up code without parallelization. \n",
    "\n",
    "**These optimizations will not reduce the runtime complexity $\\mathcal{O}(...)$ but the involved (hidden) constants!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/overview-hpc.svg\" alt=\"overview\" width=\"600px\"></td></tr>\n",
    "    <tr><td><center><sub>(c) ETH Zurich</sub></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NumPy, SciPy, NumExpr\n",
    "\n",
    "Before we discuss how to use NumPy, SciPy and NumExpr to speed up code we introduce an example which we will use in many places during this workshop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing $\\pi$ using a Monte Carlo simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The idea to compute an approximation to $\\pi$ is to generate $n$ uniformly distributed random $(x, y)$ points in a $2D$ square of side length $2$, centered at the origin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Imagine a circle inscribed into the square, i.e. the unit circle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/monte_carlo_pi.png\" width=\"450px\" ></td></tr>\n",
    "   <tr><td><center><sub>Source: <a href=\"https://www.kaggle.com/nickgould/monte-carlo-tutorial-calculating-pi/comments\">https://www.kaggle.com/nickgould/monte-carlo-tutorial-calculating-pi/comments</a></sub></center></td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The probability to generate a random point from the square in which is also located in the cirle is\n",
    "\n",
    "$$p = \\frac{A_{\\text{circle}}}{A_{\\text{square}}}$$\n",
    "\n",
    "$A_{\\text{circle}}$: Area of the circle,\n",
    "\n",
    "$A_{\\text{square}}$: Area of the square.\n",
    "\n",
    "We have a circle of radius $r = 1$, enclosed by a 2Ã—2 square. The area of the circle is $\\pi r^2=\\pi$, the area of the square is $4$. Thus\n",
    "\n",
    "<math>\\begin{align}\n",
    "p = \\frac{\\pi}{4}\n",
    "\\end{align}\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hence if we generate $n$ random points in the square and count $n_{\\text{inner}}$ points which are located in the circle:\n",
    "\n",
    "<math>\\begin{align}\n",
    "\\pi \\approx  4 \\frac{n_{\\text{inner}}}{n} \n",
    "\\end{align}\n",
    "</math>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To check if a point $(x, y)$ is located within the circle, we can use the the Euclidean formula to compute the distance $\\text{dist}$ to $(0, 0)$ and check if this distance is $\\le 1$:\n",
    "\n",
    "$$\n",
    "\\text{dist}(x, y) = \\sqrt{x^2 + y^2} \\le 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can square to both sides to avoid computing the square root and get\n",
    "\n",
    "$$\n",
    "\\text{dist}^2(x, y) = x^2 + y^2 \\le 1\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Let us simulate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts): # _ denotes a unused variable\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        # check if (x, y) lies in the cirle\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts\n",
    "\n",
    "\n",
    "# check if it works\n",
    "print(approx_pi(2_000_000))\n",
    "\n",
    "# run the timings\n",
    "%timeit approx_pi(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`for` loops are slow ðŸŒ in ðŸ! In each iteration the whole body is reinterpreted which costs time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One possibility to optimize is to reduce the amount of code and / or use [generator expressions](https://www.python.org/dev/peps/pep-0289/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What are generator expressions?\n",
    "\n",
    "> A high performance, memory efficient generalization of list comprehensions and generators.\n",
    "\n",
    "Source: [PEP 289](https://www.python.org/dev/peps/pep-0289/#id13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Example: `(i**2 for i in range(n))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "could be used wherever an iterable is accepted. In contrast to a list comprehension (see [Section 3, Appending an element to an array](../section_3/Section&nbsp;3.ipynb#Appending-an-element-to-an-array)), no temporary list is allocated in memory - the items are lazily generated on demand. Therefore they behave exactly the same as generators (see [Section 3, Generators](../section_3/Section&nbsp;3.ipynb#Generators))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi(n_attempts):\n",
    "    return (\n",
    "        4\n",
    "        / n_attempts\n",
    "        * sum(\n",
    "            uniform(-1.0, 1.0) ** 2 + uniform(-1.0, 1.0) ** 2 <= 1.0\n",
    "            for _ in range(n_attempts)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# check if it works:\n",
    "print(approx_pi(2_000_000))\n",
    "\n",
    "# run the timings\n",
    "%timeit approx_pi(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But this does not help much.\n",
    "To gain more performance, we can outsource code to C / Fortran using NumPy:\n",
    "Here, we rewrite the above ðŸ code using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def approx_pi(n_attempts):\n",
    "    # n_attempts x 2 matrix:\n",
    "    points = np.random.rand(n_attempts, 2)\n",
    "    # square values, sum horizontally and count hits:\n",
    "    n_hits = np.count_nonzero((points ** 2).sum(axis=1) <= 1.0)\n",
    "    return 4 * n_hits / n_attempts\n",
    "\n",
    "\n",
    "# check if it works:\n",
    "print(approx_pi(2_000_000))\n",
    "\n",
    "%timeit approx_pi(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is numpy faster than pure Python?\n",
    "\n",
    "* Written in C / Fortran (loops are outsourced to low level programming languages)\n",
    "* Has an own array data type containing homogeneous types (optimized memory layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/numpy_memory.svg\" width=\"800px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://www.nature.com/articles/s41586-020-2649-2/figures/1\">www.nature.com/articles/s41586-020-2649-2/figures/1</a></sub></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In contrast, here is the same realized using pure Python data structures:\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"images/python_memory.svg\" alt=\"py array memeory layout\" width=\"800px\"></td></tr>\n",
    "    <tr><td><center><sub>(c) ETH Zurich</sub></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Note:</b> <i>pandas</i> is built on top of NumPy's data structures / code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What else can we use to increase performance?\n",
    "\n",
    "Basically there are 2 approaches:\n",
    "* Stick to pure Python / optimize the interpreter (this will lead us to the concept of Just-in-time compiling, see later in the script)\n",
    "* Use a low level compiled programming language directly or indirectly (like NumPy / `pandas`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In order to understand these two approaches, we introduce the crucial concept of source code compilation.\n",
    "\n",
    "**Compilation** is a process of translating computer code written in a developer-friendly high-level *source programming language* into another a machine-friendly low-level *target programming language*. Compilation is done by a program called *compiler*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/1000px-Compiler_Shematic.png\" width=\"800px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://hpc-wiki.info/hpc/Compiler\">https://hpc-wiki.info/hpc/Compiler</a></sub></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The compiled program is optimized for the target machine to run fast on it, but be aware that the compilation itself may take quite some time and memory - the bigger the source program the longer it takes to compile it.\n",
    "\n",
    "The tradeoff when using compiled languages is: performance / flexibility in exchange for portability / usability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tradeoff: Performance / flexibility vs. portability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Performance:** When using a low level programming language, we have full control over memory management and full **flexibility** while developing algorithms. The backside is, that the amount of code will also increase drastically when compared with Python (**usability**).\n",
    "\n",
    "**Portability:** \n",
    "When writing code in a foreign language to be called from Python code, this will affect how to distribute your code:\n",
    "\n",
    "- This could be e.g. distributing a binary or source package via pypi.\n",
    "- A binary package (also called **wheel**) does not require a working C/C++/Fortran compiler on the end users computer.\n",
    "   - Such a package is built on one machine and may not use the target machines setup at maximum efficiency. \n",
    "   - You must build different wheels for each target OS, such as Linux, Mac OS X and Windows.\n",
    "- A source distribution by contrast can be optimized for the target platform but requires a working development environment including compilers. \n",
    "   - This is especially cumbersome on Windows computers. \n",
    "   - Windows does not ship with a C/C++ compiler and the compiler version must match the Python version.\n",
    "   - See also [these instructions](https://pythondev.readthedocs.io/windows.html#python-and-visual-studio-version-matrix).\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## numpy arrays in memory\n",
    "\n",
    "A NumPy array contains elements of a uniform data type, i.e. the same size for each data item, and is stored densely in a contiguous block of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "print(arr)\n",
    "print(arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T08:50:35.256393Z",
     "iopub.status.busy": "2020-10-26T08:50:35.255773Z",
     "iopub.status.idle": "2020-10-26T08:50:35.267458Z",
     "shell.execute_reply": "2020-10-26T08:50:35.265734Z",
     "shell.execute_reply.started": "2020-10-26T08:50:35.256320Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In the computer's memory, a (possibly multidimensional) array `arr` is stored as a single contiguous block. \n",
    "\n",
    "To flatten a 2 dimensional array there are two common methods:\n",
    "- `C` contiguous: flatten row per row\n",
    "- `F` (Fortran) contiguous: flatten column per column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T08:50:35.256393Z",
     "iopub.status.busy": "2020-10-26T08:50:35.255773Z",
     "iopub.status.idle": "2020-10-26T08:50:35.267458Z",
     "shell.execute_reply": "2020-10-26T08:50:35.265734Z",
     "shell.execute_reply.started": "2020-10-26T08:50:35.256320Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/contiguous_memory.png\" width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-26T08:50:35.256393Z",
     "iopub.status.busy": "2020-10-26T08:50:35.255773Z",
     "iopub.status.idle": "2020-10-26T08:50:35.267458Z",
     "shell.execute_reply": "2020-10-26T08:50:35.265734Z",
     "shell.execute_reply.started": "2020-10-26T08:50:35.256320Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**C contiguous is used in NumPy per default**: Neighbors of elements within a row are neighbors in memory. In memory, the last element of a row is a neighbor of the first element of the next row. \n",
    "\n",
    "CPUs work more efficiently when they access close memory locations (remember `L1`, `L2`, `L3` caching from section 1)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.random.rand(10_000, 10_000)\n",
    "\n",
    "# sum up first row, no need to jump in memory:\n",
    "%timeit arr[0, :].sum()\n",
    "\n",
    "# sum up first column, we have to jump in memory in steps of 10_000:\n",
    "%timeit arr[:, 0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To create an array stored in a Fortran contiguous block, you can specify the option `order='F'` when creating the array. `.flags` provides the information about the array's memory layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6]], order=\"F\") # F for \"Fortran contigous\"\n",
    "print(arr)\n",
    "arr.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.random.rand(10_000, 10_000)\n",
    "arr = np.asfortranarray(arr)\n",
    "\n",
    "# sum up first row, we have to jump in memory in steps of 10_000:\n",
    "%timeit arr[0, :].sum()\n",
    "\n",
    "# sum up first column, no need to jump in memory:\n",
    "%timeit arr[:, 0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vectorization and Universal functions (ufuncs)\n",
    "\n",
    "NumPy uses so called [ufuncs](https://numpy.org/doc/stable/reference/ufuncs.html) (universal functions) to make the repeated calculations on array elements more efficient and therefore faster. This process is also referred to as **vectorization**. For mathematical operations between arrays with the same dimension, NumPy applies the operation element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With vectorization we can avoid an explicit iteration over the array, e.g., for-loop in Python, which is rather slow. Instead the loop runs in C.\n",
    "\n",
    "Let's compare the `sum` operation in Python and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.arange(10000)\n",
    "\n",
    "%timeit np.sum(arr)\n",
    "%timeit sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From the time measurement on my computer, `np.sum` is much faster than the plain Python sum function!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compare the `np.sin` `ufunc` function from NumPy to a plain Python implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_sin(x):\n",
    "    result = np.zeros_like(x)\n",
    "    m, n = result.shape\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            result[i, j] = np.sin(x[i, j])\n",
    "    return result\n",
    "\n",
    "\n",
    "# 100 x 100 matrix\n",
    "n = 100\n",
    "# In reshape, one shape dimension can be -1.\n",
    "# In this case, the value is inferred from the length of\n",
    "# the array and remaining dimensions:\n",
    "arr = np.arange(n * n, dtype=np.float64).reshape(n, -1)\n",
    "\n",
    "%timeit apply_sin(arr)\n",
    "%timeit np.sin(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- On my computer this is a speed-up by a factor of ~150\n",
    "- The NumPy version is also much shorter and more readable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Performance of different floating point types\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "  âš  The following is highly hardware dependent!\n",
    "</div>\n",
    "\n",
    "We now compare the performance of `numpy.sin` for numpy floats of `128`, `64`, `32`, `16`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for dtype in (np.float128, np.float64, np.float32, np.float16):\n",
    "    # a bit complicated way to create an array but avoids overflows:\n",
    "    data = 0.001 * np.arange(1000, dtype=dtype).repeat(100)\n",
    "    print(dtype)\n",
    "    print(\"sum\")\n",
    "    %timeit np.sum(data)\n",
    "    print(\"sin\")\n",
    "    %timeit np.sin(data)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Broadcasting\n",
    "\n",
    "Broadcasting allows arithmetic operations in an efficient way between two arrays with different shapes or an array with a scalar. \n",
    "\n",
    "Similar to the `ufuncs` this can reduce writing Python loops which will run on C-level instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is broadcasting: we add a scalar to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.arange(6).reshape(3, -1)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(1 + arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And this also: We add a vector of shape `(3, 1)` to an array of shape `(3, 2)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add same vector to each column:\n",
    "b = np.arange(3).reshape(3, 1)\n",
    "print(b, \"+\", arr, \"=\", b + arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Or we can multiply a vector of shape `(1, 2)` with the array or shape `(3, 2)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = np.arange(1, 3).reshape(1, 2)\n",
    "print(c, \"*\", arr, \"=\", c * arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "More about broadcasting here: https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computation-on-arrays-broadcasting.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Memory allocation vs. in-place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "You have seen that using the NumPy array and its operations is efficient and, therefore, fast. However, it is possible to write an un-optimized code with NumPy as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us look at the following two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First example\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "arr = arr * 2\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second example\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "arr *= 2\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T12:54:46.643390Z",
     "iopub.status.busy": "2020-10-27T12:54:46.642995Z",
     "iopub.status.idle": "2020-10-27T12:54:46.652489Z",
     "shell.execute_reply": "2020-10-27T12:54:46.651158Z",
     "shell.execute_reply.started": "2020-10-27T12:54:46.643344Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style=\"font-weight: bold; font-size:120%;\"><i class=\"fa fa-question-circle\"></i>&nbsp; Question to the audience</p>\n",
    "\n",
    "What do you think is the difference between the above 2 operations?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The difference of the two example is that memory allocation only happens in the first example. \n",
    "\n",
    "When Python executes`arr = arr * 2`\n",
    "1. a new array for the result is created\n",
    "2. numbers in `arr` are multiplied by `2` and copied the the new array,\n",
    "3. the name `arr` is set to point to the new array\n",
    "4. eventually the data from the initial `arr` is deleted.\n",
    "\n",
    "\n",
    "In the second example, `arr *= 2` is an in-place operation. The only operation is\n",
    "\n",
    "1. numbers in `arr` are replaced by their doubled value\n",
    "\n",
    "So you can see: in-place multiplication\n",
    "\n",
    "1. does not spend time in memory management\n",
    "2. avoids the temporary increase of memory consumption by a factor of 2\n",
    "\n",
    "To check if two arrays are sharing the same data buffer, we use `np.shares_memory`. As expected, the input and output arrays do not share the same data location in the first example, while there is no array copying in the second example and the data location remains the same after the in-place operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First example: operation with array copying\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr * 2\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Second example: in-place operation\n",
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr  # Create another pointer to the original data buffer\n",
    "arr *= 2\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "In this section, we will take a look, when memory allocation happens and when not. When we understand this, we can avoid unnecessary array copying and reduce memory use during the computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### View vs. copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another example of an in-place operation is again slicing, e.g., `arr[i:j]` which is a view of the array `arr` and only points to the data buffer (not a copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr\n",
    "\n",
    "print(\"b and arr before:\", b)\n",
    "\n",
    "b[0, 1] = 888\n",
    "print(\"\\nb, arr after:\", b, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To explicitly copy an array, the easiest option is to use `.copy()`. Note that this function has `order='C'` by default. Therefore, unless specified, `.copy()` returns the output array with C-order regardless the memory structure of the input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]], order=\"F\")\n",
    "b = arr.copy()\n",
    "\n",
    "print(\"b and arr before:\", b)\n",
    "\n",
    "b[0, 1] = 888\n",
    "\n",
    "print(\"\\nb, arr after:\", b, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`np.copy()` is similar to `.copy()` but the default order is `'K'` which means match the layout of the input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]], order=\"F\")\n",
    "b = np.copy(arr)\n",
    "\n",
    "print(\"b and arr before:\", b)\n",
    "\n",
    "b[0, 1] = 888\n",
    "\n",
    "print(\"\\nb, arr after:\", b, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We have learned that indexing and slicing are only views of an array. However, advanced indexing with integer or boolean returns always a copy of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array(\n",
    "    [\n",
    "        [0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# extract elements (0, 0), (1, 0) and (1, 2):\n",
    "b = arr[[0, 1, 1], [0, 0, 2]]\n",
    "\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array(\n",
    "    [\n",
    "        [0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "    ]\n",
    ")\n",
    "b = arr[arr > 2]\n",
    "print(\"arr > 2: \", arr > 2)\n",
    "print(\"arr =\", arr)\n",
    "print(\"b =\", b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p style=\"font-weight: bold; font-size:120%;\"><i class=\"fa fa-question-circle\"></i>&nbsp; Question to the audience</p>\n",
    "\n",
    "What about the reshape operation? Does it need array copying?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following examples show reshaping an array, transposing an array and reshaping a transposed array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr.reshape(1, -1) # Second dimension automatically inferred\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr.T\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr.T.reshape(1, -1)\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Analogously to the transpose case, `.reshape()` tries to minimize copying by modifying only the metadata and does not move the data in the memory. However, it is not possible to flatten a transposed array by just modifying the metadata, and a copy is needed in this case. \n",
    "\n",
    "Other two functions which do almost the same things are `.flatten()` and `.ravel()`. They flatten a multidimensional array into a 1D array. The difference is that `.flatten()` always returns a copy of the input array collapsed into 1D, and `.ravel()` makes a copy only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr.flatten() # copy\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.array([[0, 1, 2], [3, 4, 5]])\n",
    "b = arr.ravel() # view\n",
    "print(arr)\n",
    "print(b)\n",
    "np.shares_memory(arr, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Euclidian distance matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is another problem we will see also later during the workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Starting with a set of points points\n",
    "\n",
    "$$x_1, x_2,\\ldots, x_n \\in \\mathbb{R}^k,$$\n",
    "\n",
    "the elements of their [Euclidean distance matrix](https://en.wikipedia.org/wiki/Euclidean_distance_matrix) $A$ are given by squares of pair-wise distances between them.\n",
    "\n",
    "$$A_{ij} = \\text{dist}(x_i, x_j)^2 = \\text{d}_{i,j}^2 = \\|x_i - x_j\\|^2,$$\n",
    "\n",
    "where $\\|p\\|$ denotes the [Euclidean norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm) on $\\mathbb{R}^k$\n",
    "\n",
    "$$\n",
    "\\|p\\| = \\sqrt{p_1^2 + \\ldots + p_k^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<math>\\begin{align}A = \\begin{bmatrix}\n",
    "0 & d_{12}^2 & d_{13}^2 & \\dots & d_{1n}^2 \\\\\n",
    "d_{21}^2 & 0 & d_{23}^2 & \\dots & d_{2n}^2 \\\\\n",
    "d_{31}^2 & d_{32}^2 & 0 & \\dots & d_{3n}^2 \\\\\n",
    "\\vdots&\\vdots & \\vdots & \\ddots&\\vdots&  \\\\\n",
    "d_{n1}^2 & d_{n2}^2 & d_{n3}^2 & \\dots & 0 \\\\\n",
    "\\end{bmatrix}\\end{align} </math>\n",
    "\n",
    "The task is to compute  $A$, given a set of $n$ $k$-dimensional points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_points(n):\n",
    "    \"\"\"create n points in 3d for testing\"\"\"\n",
    "    points = []\n",
    "    for i in range(0, 3 * n, 3):\n",
    "        points.append((float(i), 1 + float(i // 2), 1 + float(i // 3)))\n",
    "    return points\n",
    "\n",
    "\n",
    "def dist_squared(a, b):\n",
    "    return (a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2 + (a[2] - b[2]) ** 2\n",
    "\n",
    "\n",
    "def dist_matrix(points):\n",
    "    rows = []\n",
    "    for p in points:\n",
    "        row = []\n",
    "        for q in points:\n",
    "            row.append(dist_squared(p, q))\n",
    "        rows.append(row)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = setup_points(4)\n",
    "for i, row in enumerate(points):\n",
    "    print(\"point\", i, \":\", row)\n",
    "print()\n",
    "\n",
    "M = dist_matrix(points)\n",
    "\n",
    "print(\"pairwise distances:\")\n",
    "for row in M:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = setup_points(1000)\n",
    "%timeit M = dist_matrix(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-04T19:20:50.298223Z",
     "iopub.status.busy": "2020-11-04T19:20:50.297917Z",
     "iopub.status.idle": "2020-11-04T19:20:50.304271Z",
     "shell.execute_reply": "2020-11-04T19:20:50.303034Z",
     "shell.execute_reply.started": "2020-11-04T19:20:50.298187Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Runtime complexity**: $O(n^2)$ which we cannot improve because we have to iterate over all $n^2$ pairs of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-04T19:20:50.298223Z",
     "iopub.status.busy": "2020-11-04T19:20:50.297917Z",
     "iopub.status.idle": "2020-11-04T19:20:50.304271Z",
     "shell.execute_reply": "2020-11-04T19:20:50.303034Z",
     "shell.execute_reply.started": "2020-11-04T19:20:50.298187Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### First optimization\n",
    "\n",
    "To make the code faster we try to use NumPy to get rid of one or both of the Python loops involved and to replace number wise computations by vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = np.array(setup_points(3))\n",
    "\n",
    "print(\"points matrix with shape\", points.shape)\n",
    "print(points)\n",
    "\n",
    "p0 = points[0, :]\n",
    "print(\"\\nfirst point with shape\", p0.shape)\n",
    "print(p0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Although `points` and `p0` have different dimensions, the expression `points - p0` is defined and can be computed using NumPy broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"broadcasting in action: matrix minus first row\")\n",
    "print(points - p0)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Result: the $i$-th row of `points - p0` is the difference of $p_i$ and $p_0$. \n",
    "To compute the squared distance we have to square values and then add them up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"squared values\")\n",
    "print((points - p0) ** 2)\n",
    "print()\n",
    "\n",
    "print(\"horizontal sum\")\n",
    "print(((points - p0) ** 2).sum(axis=1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The last vector is the first row of the distance matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**The horizontal sum computed the squared distance of $p_0$ to all other points!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To compute the full distance matrix  we loop `p0` over all rows or the points matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dist_matrix_broadcast(points):\n",
    "    points = np.array(points)\n",
    "    result = []\n",
    "    for p0 in points:\n",
    "        distances_to_p0 = ((points - p0) ** 2).sum(axis=1)\n",
    "        result.append(distances_to_p0)\n",
    "    return np.array(result)\n",
    "\n",
    "\n",
    "print(dist_matrix_broadcast(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compare timings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = setup_points(1_000)\n",
    "\n",
    "%timeit dist_matrix(p)\n",
    "%timeit dist_matrix_broadcast(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**THIS IS ABOUT 20 times faster!!!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Can we do better?\n",
    "\n",
    "There is still one Python loop involved! Can we get rid of this by using broadcasting or vectorization also?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The following solution is now **more advanced**, we will not explain this in detail since there is a bit more math involved and you might want to read this and work out the details later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Trick**: apply a generalization of the 2nd binomial formula\n",
    "\n",
    "$$\n",
    "\\mathrm{dist}(a, b)^2 = \\| a - b \\|^2 =\\|a\\|^2 - 2 \\left<a, b\\right> +  \\|b\\|^2\n",
    "$$ \n",
    "\n",
    "where $\\left< a, b \\right>$ is the scalar product of the vectors $a$ and $b$. This leads to the following implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dist_matrix_no_for_loop(points):\n",
    "    # To avoid computing the same multiple times, use:\n",
    "    # <x-y, x-y> = <x,x> -2 <x,y> + <y,y>\n",
    "\n",
    "    points = np.array(points)\n",
    "    p_2 = (points ** 2).sum(axis=1)\n",
    "\n",
    "    # Note: The following is a slightly more efficient way\n",
    "    # of writing (points**2).sum(axis=1):\n",
    "    # p_2 = np.einsum(\"ij,ij->i\", points, points)\n",
    "\n",
    "    x_2 = p_2[:, None]\n",
    "    y_2 = p_2[None, :]\n",
    "\n",
    "    # @ is matrix multiplication, afterwards\n",
    "    # entry (i, j) of x_y is <p_i, p_j> !!!\n",
    "    x_y = points @ points.T\n",
    "\n",
    "    # broadcast x_2 of shape (n, 1), x_y of shape (n, n)\n",
    "    # and y_2 of shape (1, n):\n",
    "    return x_2 - 2 * x_y + y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for correctness\n",
    "print(dist_matrix_no_for_loop(setup_points(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = setup_points(1_000)\n",
    "\n",
    "%timeit dist_matrix(p)\n",
    "%timeit dist_matrix_broadcast(p)\n",
    "%timeit dist_matrix_no_for_loop(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we gained another factor of 4-5!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**You found the last example difficult to read and understand?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We warned you in section 1 already that optimized code can be complicated and hard to read!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"images/4t7moh.jpg\" width=20%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last but not least SciPy also offers a function to compute distance matrices, this function is completely implemented in C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def dist_matrix_scipy(points):\n",
    "    return cdist(points, points, \"sqeuclidean\")\n",
    "\n",
    "\n",
    "%timeit dist_matrix_scipy(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let us run a final runtime analysis to compare all four approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def measure_time(method, n):\n",
    "    p = setup_points(n)\n",
    "    times = []\n",
    "    for _ in range(3):\n",
    "        s = time.time()\n",
    "        method(p)\n",
    "        times.append(time.time() - s)\n",
    "    return min(times)\n",
    "\n",
    "\n",
    "def measure_and_plot_times(ns, method, style):\n",
    "    times = [measure_time(method, n) for n in ns]\n",
    "    plt.plot(ns, times, style, label=method.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ns = (10, 100, 500, 750, 1000, 1500, 2000, 3000, 4000)\n",
    "\n",
    "plt.figure(figsize=(9, 6))\n",
    "measure_and_plot_times(ns[:6], dist_matrix, \"r:\")\n",
    "measure_and_plot_times(ns, dist_matrix_broadcast, \"g:\")\n",
    "measure_and_plot_times(ns, dist_matrix_no_for_loop, \"b:\")\n",
    "measure_and_plot_times(ns, dist_matrix_scipy, \"y:\")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Conclusion**: Runtime complexity of all three implementations is $n^2$ but with significantly different factors / constants!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NumExpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> NumExpr is a fast numerical expression evaluator for NumPy. With it, expressions that operate on arrays (like `3*a+4*b`) are accelerated and use less memory than doing the same calculation in Python.\n",
    "> In addition, its multi-threaded capabilities can make use of all your cores â€“ which generally results in substantial performance scaling compared to NumPy.\n",
    "> Last but not least, NumExpr can make use of Intelâ€™s VML (Vector Math Library, normally integrated in its Math Kernel Library, or MKL). This allows further acceleration of transcendent expressions.\n",
    "<table>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://pypi.org/project/numexpr/\">pypi.org/project/numexpr/</a></sub></center></td></tr>\n",
    "</table>\n",
    "\n",
    "Documentation: [numexpr.readthedocs.io](https://numexpr.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Features**\n",
    "* Avoids temporary memory copy / allocations\n",
    "* Is more clever to avoid cache misses on cpu (see Sec 1)\n",
    "\n",
    "Lets review the Euclidean distance example (NumPy version):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def dist_matrix_no_for_loop(points):\n",
    "    points = np.array(points)\n",
    "    p_2 = np.einsum(\"ij,ij->i\", points, points)\n",
    "    x_2 = p_2[:, None]\n",
    "    y_2 = p_2[None, :]\n",
    "    x_y = points @ points.T\n",
    "    return x_2 - 2 * x_y + y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "In the last line the expression `x_2 - 2 * x_y + y_2` involves 3 memory allocations internally, as NumPy computes this expression in several intermediate steps:\n",
    "\n",
    "1. Compute `tmp_1 = 2 * x_y`\n",
    "2. Compute `tmp_2 = x_2 - tmp_1`\n",
    "3. Compute `result = tmp_2 + y_2`.\n",
    "\n",
    "For each intermediate result, a new vector will be allocated and the result of the arithmetic operation will be stored into it.\n",
    "\n",
    "The library NumExpr solves this problem. It can compile a vector expression into code involving only one memory allocation (in the case of an inline operation even zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numexpr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dist_matrix_numexpr(points):\n",
    "    points = np.array(points)\n",
    "    p_2 = np.einsum(\"ij,ij->i\", points, points)\n",
    "    x_2 = p_2[:, None]\n",
    "    y_2 = p_2[None, :]\n",
    "    x_y = points @ points.T  # @ is matrix multiplication\n",
    "    return numexpr.evaluate(\"x_2 - 2*x_y + y_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "points = setup_points(10_000)\n",
    "%timeit dist_matrix_no_for_loop(points)\n",
    "%timeit dist_matrix_numexpr(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We now also compare the memory consumption of both versions. We will only compare the part which differs between the two versions and prepare the variables used there first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler\n",
    "\n",
    "points = np.array(points)\n",
    "\n",
    "p_2 = np.einsum(\"ij,ij->i\", points, points)\n",
    "x_2 = p_2[:, None]\n",
    "y_2 = p_2[None, :]\n",
    "x_y = points @ points.T  # @ is matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%memit -r 10  x_2 - 2 * x_y + y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%memit -r 10  numexpr.evaluate(\"x_2 - 2*x_y + y_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "So, using NumExpr, we get some small improvement in performance and can reduce memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "* How to outsource ðŸŒ `for` loops to ðŸš€ low level libraries\n",
    "* How to avoid unnecessary memory allocations (temporaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/and-now-for-something-completely-different.jpg\" width=\"400px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://www.themoviedb.org/movie/9267-and-now-for-something-completely-different\">www.themoviedb.org</a></sub></center></td></tr>\n",
    "</table>\n",
    "\n",
    "> For a Schwarzschild black hole (a black hole with no rotation or electromagnetic charge), given a free fall particle starting at the event horizon, the maximum propper time (which happens when it falls without angular velocity) it will experience to fall into the singularity is `Ï€*M` (in natural units), where M is the mass of the black hole. For Sagittarius A* (the black hole at the centre of the milky way) this time is approximately 1 minute.\n",
    "\n",
    "> Schwarzschild black holes are also unique because they have a space-like singularity at their core, which means that the singularity doesn't happen at a specific point in *space* but happens at a specific point in *time* (the future). This means once you are inside the event horizon you cannot point with your finger towards the direction the singularity is located because the singularity happens in your future: no matter where you move, you will \"fall\" into it.\n",
    "\n",
    "Source: [pythoninsider: Python 3.10 announcement](https://pythoninsider.blogspot.com/2021/10/python-3100-is-available.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# JIT: just-in-time compilation\n",
    "\n",
    "Recall, that **compilation** is a process of translating computer code written in a developer-friendly high-level *source programming language* into a machine-friendly low-level *target programming language*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Compilation of large source code may take a lot of time. How about instead of compiling the whole source code, we compile only the slow parts of the code, and only before they are actually executed for the first time? That's the main idea behind the Just-In-Time (JIT) compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "<dl>\n",
    "    <dt><strong>Just-In-Time (JIT) compilation</strong></dt>\n",
    "    <dd>For interpreted languages, like Python, it is possible to <em>compile (parts) of the source code on-demand (on their first run)</em>.\n",
    "    Most JIT compilers analyze code during the first execution and created more efficient code for later executions.\n",
    "    </dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "## How does JIT work? An illustrative example\n",
    "\n",
    "Discalimer: **The following example is neither accurate nor real, it serves only an educational purpose**.\n",
    "\n",
    "We implement a generic function to add up a collection of items for which `+` is defined, e.g. numbers or strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_up(values):\n",
    "\n",
    "    if len(values) < 1:\n",
    "        return None\n",
    "\n",
    "    sum_ = values[0]\n",
    "    for el in values[1:]:\n",
    "        sum_ += el\n",
    "\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "We know from the Section 1 that Python is slow here because `+` is implemented for multiple types: one can add strings, numbers or any other object that implements own addition operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray_values = np.arange(100_000)\n",
    "\n",
    "%timeit add_up(ndarray_values)\n",
    "\n",
    "add_up(ndarray_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "A JIT compiler might trace that this function was used with a `numpy` array and then generate optimized code on the fly. The compiler will not change your source code but use internally another implementation in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_up(values):\n",
    "    if isinstance(values, np.ndarray):\n",
    "        return np.sum(values)\n",
    "\n",
    "    if len(values) < 1:\n",
    "        return None\n",
    "\n",
    "    sum_ = values[0]\n",
    "    for el in values[1:]:\n",
    "        sum_ += el\n",
    "\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "So when you call the function again you will automatically use a hopefully faster **specialized implementation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit add_up(ndarray_values)\n",
    "\n",
    "add_up(ndarray_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This happens incrementally, so calling again the same function but with a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "str_values = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "add_up(str_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "might make JIT compiler to come up with sth more specialized for this case, like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_up(values):\n",
    "    if isinstance(values, np.ndarray):\n",
    "        return np.sum(values)\n",
    "\n",
    "    if len(values) < 1:\n",
    "        return None\n",
    "\n",
    "    # educational purpose only: a slow per-item type check\n",
    "    if all(isinstance(item, str) for item in values):\n",
    "        return \"\".join(values)\n",
    "\n",
    "    sum_ = values[0]\n",
    "    for el in values[1:]:\n",
    "        sum_ += el\n",
    "\n",
    "    return sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_up(str_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In this simple example the optimizations happened on the highest level of our main function. In real life, this sum could happen nested deep in some other loops or `if`/`elif`/`else` branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The order of operations from the entry-point of the function to the result is called an **execution path**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Real JIT compilation** is much more elaborate than this previous example but the basic idea is:\n",
    "\n",
    "- record information such as types along an execution path, and\n",
    "- try to replace (part of) the execution path by a faster specialized version, based on the recorded information.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "  âš  In case these optimizations happen in memory they will be forgotten when you start the program again.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## PyPy\n",
    "\n",
    "<blockquote>\n",
    "  <p>.. if you want your code to just magically run faster, you should probably just use PyPy ..</p>\n",
    "    <footer>\n",
    "        â€”Guido van Rossum (creator of Python), <cite>PyCon 2015 talk</cite>\n",
    "        <table>\n",
    "            <tr><td><center><img src=\"images/guido.jpg\" width=\"200px\"></center></td></tr>\n",
    "            <tr><td><center><sub>Source: <a href=\"https://commons.wikimedia.org/w/index.php?curid=4974869\">https://commons.wikimedia.org/w/index.php?curid=4974869</a></sub></center></td></tr>\n",
    "        </table>\n",
    "    </footer>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "| | | |\n",
    "|-|-|-|\n",
    "| ![](images/logos/py-flat.svg) | Reference Python language implementation| C- and Python-implemented CPython interpreter (\\*) |\n",
    "| ![](images/logos/pypy.svg) | **[PyPy](https://www.pypy.org/) (Python in Python)** | alternative Python-implemented (\\*\\*) interpreter for Python code that always performs JIT-compilation |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "<p style=\"font-size: smaller;\">(*) CPython behaves like an interpreter, running directly the given source code, but it actually also performs a cached-compilation, creating intermediate bytecode - the <code>.pyc</code> files in <code>__pycache__</code> folder - which is run by CPython's virtual machine.</p>\n",
    "\n",
    "<p style=\"font-size: smaller;\">(**) PyPy is actually implemented in <a href=\"https://rpython.readthedocs.io/en/latest/\">RPython (Restricted Python)</a> - a subset of Python language, which can directly be compiled to C. RPython requires e.g. that a variable's type can be inferred at compile time.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**How does it work?**\n",
    "\n",
    "PyPy interprets your code as it runs to an intermediate JIT-aware bytecode, recording meanwhile what the interpreter does. PyPy identifies the frequently executed parts of the bytecode (foremost, the often executed loops) which are JIT-compiled to a fast running machine-specific code.\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"images/PyPy_compilation.jpg\" width=\"500px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://www.geeksforgeeks.org/difference-various-implementations-python/\">https://www.geeksforgeeks.org/difference-various-implementations-python/</a></sub></center></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "â„¹ You can simply try using PyPy instead of CPython to get your Python code run few times faster.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Let's try it out with the values adding up illustrative example. Let's write it to file to use the PyPy interpreter instead of the default CPython interpreter. Let's also add some extra timing prints for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pypy -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "To compare `PyPy` to `CPython` in a notebook we must write the Python code to a file and then call `pypy` resp. `python` from the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file add_up.py\n",
    "import time\n",
    "\n",
    "def add_up(values):\n",
    "    t_start = time.time()\n",
    "\n",
    "    if len(values) < 1:\n",
    "        return None\n",
    "\n",
    "    sum_ = values[0]\n",
    "    for el in values[1:]:\n",
    "        sum_ += el\n",
    "\n",
    "    print(f\"sum = {sum_}\")\n",
    "    print(f\"time: {time.time() - t_start:g}s\")\n",
    "    print()\n",
    "\n",
    "    return sum_\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t_start = time.time()\n",
    "    int_values = list(range(10_000_000))\n",
    "    for _ in range(3):\n",
    "        add_up(int_values)\n",
    "\n",
    "    print(f\"total time: {time.time() - t_start:g}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!time python add_up.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!time pypy add_up.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let's also compare real run time for the Euclidian distance matrix example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pycat ../../examples/euclidean_distance.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"CPython interpreter:\")\n",
    "print()\n",
    "!time python ../../examples/euclidean_distance.py\n",
    "print()\n",
    "print(\"PyPy interpreter:\")\n",
    "print()\n",
    "!time pypy ../../examples/euclidean_distance.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "[PyPy cannot re-use a previously compiled code](https://doc.pypy.org/en/latest/faq.html#couldn-t-the-jit-dump-and-reload-already-compiled-machine-codehttps://doc.pypy.org/en/latest/faq.html#couldn-t-the-jit-dump-and-reload-already-compiled-machine-code), i.e. it always JIT compiles the code, but **even with the JIT compilation overhead always added, PyPy often runs faster**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  âš  Since PyPy compiles different traces of a function, memory requirements of function objects are higher than these of CPython\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file min_mem_profile.py\n",
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def temporary_array():\n",
    "    return\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    temporary_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --user memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pypy min_mem_profile.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  âš  Although popular \"C-heavy\" scientific libraries like <code>NumPy</code> and <code>SciPy</code> support modern <code>PyPy</code>, using such <a href=\"https://doc.pypy.org/en/latest/faq.html#do-c-extension-modules-work-with-pypy\">Python C-extensions might be slower when used with PyPy</a>, mostly due to a start-up overhead\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file add_up_numpy.py\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def add_up(values):\n",
    "    t_start = time.time()\n",
    "\n",
    "    sum_ = np.sum(values)\n",
    "\n",
    "    print(f\"sum = {sum_}\")\n",
    "    print(f\"time: {time.time() - t_start:g}s\")\n",
    "    print()\n",
    "\n",
    "    return sum_\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t_start = time.time()\n",
    "    ndarray_values = np.arange(10_000_000)\n",
    "    for _ in range(3):\n",
    "        add_up(ndarray_values)\n",
    "    print(f\"total time: {time.time() - t_start:g}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!time python add_up_numpy.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!time pypy add_up_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "  âš  <a href=\"https://www.pypy.org/compat.html\">PyPy compatiblity with Python language is restricted</a> - <strong>your code most likely won't compile out-of-the-box if</strong>\n",
    "<ul>\n",
    "    <li>it uses CPython extensions, which are not implemented to work with <code>PyPy</code>, most often implicitly via popular dependencies like <code>pandas</code> or <code>scikit-learn</code>,</li>\n",
    "    <li>it uses modern Python features (*),</li>\n",
    "    <li>...</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<p style=\"font-size: smaller;\">\n",
    "(*) On 5 Aug 2022, Python stable release is 3.10, whereas <a href=\"https://www.pypy.org/download.html\">PyPy only supports Python 3.9</a>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <p>â„¹&nbsp;<strong>PyPy works best with pure Python code</strong>.</p>\n",
    "    <p>PyPy is a <em>low-hanging fruit</em>: easy to install, and when it works, it works well, but there is a high chance it won't work out-of-the-box with external libraries.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Numba\n",
    "\n",
    "[Numba](https://numba.pydata.org) is a JIT compiler that translates manually designated Python functions into  machine code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "* uses explicit decorators for functions, like `@numba.jit`, to indicate JIT compilation,\n",
    "* supports NumPy arrays,\n",
    "* supports CPU and GPU parallelization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "**How does it work?**\n",
    "\n",
    "Numba is built on a [LLVM compiler infrastructure](https://llvm.org/) (*), in particular on LLVM JIT compiler and on LLVM Intermediate Representation (IR). IR is the data structure or code used internally by a compiler (or a virtual machine) to represent source code.\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"images/Python_Numba_LLVM.png\" width=\"600px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://ep2019.europython.eu/talks/hsbcAZF-understanding-numba-the-python-and-numpy-compiler/\">https://ep2019.europython.eu/talks/hsbcAZF-understanding-numba-the-python-and-numpy-compiler/</a></sub></center></td></tr>\n",
    "</table>\n",
    "    \n",
    "<p style=\"font-size: smaller;\">(*) The LLVM compiler infrastructure is used in compilers for various languages such as <a href=\"https://clang.llvm.org\">Clang</a> for C/C++ or <code>rustc</code> for <a href=\"https://www.rust-lang.org\">Rust</a>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### `@numba.jit` application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Recall the example to approximate $\\pi$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        # check if (x, y) lies in the cirle\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To mark and prepare a function for Numba JIT compilation, decorate it with `numba.jit` decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "\n",
    "@numba.jit\n",
    "def approx_pi_jit(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        # check if (x, y) lies in the cirle\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let us check how this small modifiation impacts run time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi(5000)\n",
    "%timeit approx_pi_jit(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "On first run the actual LLVM JIT compilation happens and this can be relatively slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "You see in the following example the timing differences between first and following runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the next two lines make sure that the previous JIT\n",
    "# compilation is \"forgotten\" in the notebook:\n",
    "del approx_pi_jit\n",
    "approx_pi_jit = numba.jit(approx_pi)\n",
    "\n",
    "print(\"first run\")\n",
    "\n",
    "# run exactly once:\n",
    "%timeit -r1 -n1 approx_pi_jit(5000)\n",
    "\n",
    "print()\n",
    "print(\"second run\")\n",
    "%timeit -r1 -n1 approx_pi_jit(5000)\n",
    "\n",
    "print()\n",
    "print(\"third run\")\n",
    "%timeit -r1 -n1 approx_pi_jit(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### *Object* and *No Python* modes\n",
    "        \n",
    "Numba supports compilation of only some features of the Python language; it does not support e.g. \n",
    "\n",
    "- dictionaries, (a Numba specific `dict` replacement is [avaible as an experimental feature](https://numba.pydata.org/numba-doc/0.43.0/reference/pysupported.html#dict)),\n",
    "- generators or comprehensions (cf. [Numba's Supported Python features](https://numba.readthedocs.io/en/stable/reference/pysupported.html))\n",
    "- lists of mixed types, see [here](https://numba.pydata.org/numba-doc/0.43.0/reference/pysupported.html#list) or [lists of lists](https://numba.pydata.org/numba-doc/0.43.0/reference/pysupported.html#list-reflection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In case Numba can not compile a feature, it will use the so called **Object mode**. This mode allows your program to run, but it **does not use JIT compilation when a non-supported Python feature is encountered**. In turn, Numba might actually make your program significanty slower (as the compiled code needs to communicate back and forth with the Python interpreter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "By default when using `@numba.jit` Numba uses the Object mode. Instead, you can try to force the **No Python** mode by using `nopython=True` option, or equivalently `@numba.njit`. In the No Python mode Numba **always tries to JIT compile decorated code and triggers an error when a non-supported Python feature is encountered**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "\n",
    "@numba.njit  # same as: @numba.jit(nopython=True)\n",
    "def approx_pi_jit(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        # check if (x, y) lies in the cirle\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_jit(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "It's a good practice to always try to force No Python mode. You will get an error, when Numba does not understand some functions or objects, like e.g. `pandas` `DataFrame` .. but only on JIT compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numba\n",
    "import pandas as pd\n",
    "\n",
    "def use_pandas(nrow=1_000):\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"x\": random.sample(range(nrow), k=nrow),\n",
    "            \"y\": random.sample(range(nrow), k=nrow),\n",
    "        }\n",
    "    )\n",
    "    return (df ** 2).sum().sum()\n",
    "\n",
    "# alternative use of njit:\n",
    "use_pandas_jit = numba.njit(use_pandas)\n",
    "\n",
    "try: use_pandas_jit()\n",
    "except Exception as e: print(\"ðŸ’¥\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Good practice</b>: always use <code>@numba.njit</code> instead of <code>@numba.jit</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    âš  When using Object mode and when Numba does not understand used objects, like e.g. the <code>pandas</code> data frames, you will get a warning, but no error, and the code won't really be faster\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "It might even run slower due to the Numba's overhead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explicitly force Object mode to remove warnings\n",
    "# try without forcing Object mode w/ plain @numba.jit\n",
    "use_pandas_jit = numba.jit(forceobj=True)(use_pandas)\n",
    "\n",
    "print(\"Python:\\n\", use_pandas())\n",
    "%timeit -n 32 use_pandas()\n",
    "print(\"\\nNumba JIT compilation:\")\n",
    "%time use_pandas_jit()\n",
    "print(\"\\nNumba:\\n\", use_pandas_jit())\n",
    "%timeit -n 32 use_pandas_jit()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T17:34:59.440626Z",
     "iopub.status.busy": "2020-11-11T17:34:59.439875Z",
     "iopub.status.idle": "2020-11-11T17:34:59.457491Z",
     "shell.execute_reply": "2020-11-11T17:34:59.455125Z",
     "shell.execute_reply.started": "2020-11-11T17:34:59.440553Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### numpy support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T17:32:27.957460Z",
     "iopub.status.busy": "2020-11-11T17:32:27.956606Z",
     "iopub.status.idle": "2020-11-11T17:32:27.991651Z",
     "shell.execute_reply": "2020-11-11T17:32:27.985658Z",
     "shell.execute_reply.started": "2020-11-11T17:32:27.957093Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Numba seamlessly supports large part of NumPy (cf. [Supported numpy features](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "import numpy as np\n",
    "\n",
    "def use_numpy():\n",
    "    a = np.random.randint(0, 10, size=(1000, 2))\n",
    "    return (a ** 2).sum()\n",
    "\n",
    "# force non-Python mode\n",
    "use_numpy_jit = numba.njit(use_numpy)\n",
    "\n",
    "print(\"Python:\")\n",
    "%timeit -n 32 use_numpy()\n",
    "print(\"\\nNumba JIT compilation:\")\n",
    "%time use_numpy_jit()\n",
    "print(\"\\nNumba:\")\n",
    "%timeit -n 32 use_numpy_jit()\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Vectorize = Numpy `ufunc`**\n",
    "\n",
    "Additionally, Numba provides [`@vectorize`](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#vectorize) ([`@guvectorize`](https://numba.pydata.org/numba-doc/latest/user/vectorize.html#guvectorize)) decorators to make it easy to define own NumPy (generalized) universal functions (`ufunc`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numba type signature for types inference;\n",
    "# (cf. https://numba.pydata.org/numba-doc/latest/reference/types.html)\n",
    "\n",
    "# here: take two 64-bit integers and return a 64-bit float\n",
    "@numba.vectorize([\"float64(int64, int64)\"])\n",
    "def divide_ints(x, y):\n",
    "    if y == 0:\n",
    "        if x == 0:\n",
    "            return np.nan\n",
    "        return np.sign(x) * np.inf\n",
    "    return x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"scalar / scalar\")\n",
    "print(divide_ints(2, 2))\n",
    "\n",
    "print(\"\\nscalar / vector\")\n",
    "print(divide_ints(1, [0, 2, 1]))  # scalar / vector\n",
    "\n",
    "print(\"\\nvector / vector\")\n",
    "print(divide_ints([1, 2], [2, 1]))  # element-wise vector / vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\nbroadcast\")\n",
    "x = np.arange(3).reshape(3, 1)\n",
    "y = np.arange(9).reshape(3, 3)\n",
    "print(divide_ints(x, y))\n",
    "\n",
    "print(\"\\nufunc.outer\")\n",
    "print(divide_ints.outer([1, 2], [2, 3, 4]))  # all vs. all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The arguments types of Numba-vectorized functions are validated to agree with `@numba.vectorize` declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "divide_ints(2.1, 1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-11T18:05:23.844521Z",
     "iopub.status.busy": "2020-11-11T18:05:23.834774Z",
     "iopub.status.idle": "2020-11-11T18:05:23.883071Z",
     "shell.execute_reply": "2020-11-11T18:05:23.880785Z",
     "shell.execute_reply.started": "2020-11-11T18:05:23.844431Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Parallelization\n",
    "\n",
    "To make use of multi-core CPU architecture, add a `parallel=True` option to the decorator and, in `for` loops replace `range()` with `numba.prange()`, but **only for *embarrassingly parallel* or reduction/accumulation-based computations**.\n",
    "\n",
    "Let's compare the serial and parallel variantes of the \"numbified\"  $\\pi$ approximation example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "import numba\n",
    "\n",
    "@numba.njit\n",
    "def approx_pi_jit(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@numba.njit(parallel=True)\n",
    "def approx_pi_par(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in numba.prange(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts\n",
    "\n",
    "\n",
    "print(approx_pi_jit(2_000_000))\n",
    "print(approx_pi_par(2_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = 2_000_0000\n",
    "\n",
    "%timeit approx_pi_jit(n)\n",
    "for n_threads in (2, 3, 4, 8):\n",
    "    print()\n",
    "    print(f\"and on #threads = {n_threads}\")\n",
    "    print()\n",
    "    numba.set_num_threads(n_threads)\n",
    "    %timeit approx_pi_par(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    âš  <code>for</code> loops are not in general easily parallelized (<it>embarassingly parallel</it>) as shown above\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numba\n",
    "\n",
    "\n",
    "def fibonacci_loop(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "\n",
    "    prev_prev_fib = 0\n",
    "    prev_fib = 1\n",
    "    for i in range(2, n + 1):\n",
    "        fib = prev_fib + prev_prev_fib\n",
    "        prev_prev_fib = prev_fib\n",
    "        prev_fib = fib\n",
    "    return prev_fib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WRONG use of `parallel=True` and `numba.prange`\n",
    "@numba.njit(parallel=True)\n",
    "def fibonacci_loop_numba_wrong(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "\n",
    "    prev_prev_fib = 0\n",
    "    prev_fib = 1\n",
    "    for i in numba.prange(2, n + 1):\n",
    "        fib = prev_fib + prev_prev_fib\n",
    "        prev_prev_fib = prev_fib\n",
    "        prev_fib = fib\n",
    "    return prev_fib\n",
    "\n",
    "print(\"Expecting:\", fibonacci_loop(35))\n",
    "print(\"Got:\", fibonacci_loop_numba_wrong(35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Parallel `ufunc`s**\n",
    "\n",
    "\n",
    "You can also \"target\" the Numba-vectorized functions for multi-core CPU or even GPU by specifying `target=\"parallel\"` or `target=\"cuda\"`.\n",
    "\n",
    "For demonstration purposes, let's make the $\\pi$ approximation function a `ufunc` (vectorized over number of attempts), both serial and parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "import numba\n",
    "\n",
    "\n",
    "@numba.vectorize(\"float64(int64,)\")\n",
    "def approx_pi_vec(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@numba.vectorize(\"float64(int64,)\", target=\"parallel\")\n",
    "def approx_pi_vec_par(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = [2_000_000] * 4\n",
    "\n",
    "print(\"#### vectorized pi approximation\")\n",
    "print(approx_pi_vec(v))\n",
    "%timeit approx_pi_vec(v)\n",
    "\n",
    "for n_threads in (2, 3, 4, 6, 8):\n",
    "    print()\n",
    "    print(f\"#### vectorized pi approximation with {n_threads} threads\")\n",
    "    numba.set_num_threads(n_threads)\n",
    "    print(approx_pi_vec_par(v))\n",
    "    %timeit approx_pi_vec_par(v)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    âš  parallelization of Numba-vectorized <code>ufunc</code> parallelization has some shortcomings, e.g. <a href=\"https://github.com/numba/numba/issues/1721\">producing wrong results when using <code>ufunc.accumulate</code> or <code>ufunc.reduce</code> on a Numba-vectorized parallel function</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Threading Layers**\n",
    "\n",
    "[Numba's Threading Layers](https://numba.pydata.org/numba-doc/latest/user/threading-layer.html) are the backend libraries that perform the parallel execution; except for the default built-in task scheduler, Numba supports **Intel TBB** and **OpenMP** parallel programming libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "You can get the threading_layer with\n",
    "\n",
    "```python\n",
    "from numba import threading_layer; @numba.njit(parallel=True) ...; print(threading_layer())\n",
    "```\n",
    "\n",
    "See [here](https://numba.pydata.org/numba-doc/latest/user/threading-layer.html#the-threading-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Good to know\n",
    "\n",
    "Options:\n",
    "\n",
    "* [`cache=True`](https://numba.pydata.org/numba-doc/dev/user/jit.html#cache) - save compiled code to share with later Python interpreter invocations (note: this is caching, of a compiled function code, and not memoization, of function return values; cf. Section 3)\n",
    "* [`fastmath=True`](https://numba.pydata.org/numba-doc/latest/user/performance-tips.html#fastmath) - trade accuracy (IEEE-defined compliance, e.g. loop operations order) for even more speed\n",
    "* [`nogil=True`](https://numba.pydata.org/numba-doc/dev/user/jit.html#jit-nogil) - release GIL e.g. in functions that explicitly manage threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Decorators:\n",
    "\n",
    "* [`@jitclass`](https://numba.pydata.org/numba-doc/latest/user/jitclass.html#jitclass) - create a JIT-aware classes (early version)\n",
    "* [`@cfunc`](https://numba.pydata.org/numba-doc/latest/user/cfunc.html#cfunc) - create a C callback to use in an external C library\n",
    "* [`@cuda.jit`](https://numba.pydata.org/numba-doc/latest/cuda/kernels.html) - NVIDIA CUDA kernel to run on GPUs (will be shown later)\n",
    "* [`@stencil`](https://numba.pydata.org/numba-doc/latest/user/stencil.html#numba-stencil) - array neighborhood computations (stencil-like operation kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise 1 [10 min]\n",
    "\n",
    "*Numbify* the the NumPy variant of the $\\pi$ hit'n'miss approximation example. Which of the Numba, NumPy, `numpy+Numba` variants performs best? How about after multi-core parallelization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def approx_pi_numpy(n_attempts):\n",
    "    points = np.random.rand(n_attempts, 2)\n",
    "    n_hits = np.count_nonzero((points ** 2).sum(1) <= 1.0)\n",
    "    return 4 * n_hits / n_attempts\n",
    "\n",
    "%timeit approx_pi(5000)\n",
    "%timeit approx_pi_numpy(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T10:26:12.146005Z",
     "iopub.status.busy": "2020-11-12T10:26:12.141867Z",
     "iopub.status.idle": "2020-11-12T10:26:12.353431Z",
     "shell.execute_reply": "2020-11-12T10:26:12.308940Z",
     "shell.execute_reply.started": "2020-11-12T10:26:12.145936Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise 2 [10 min]\n",
    "\n",
    "*Numbify*, in the *No Python* mode, the NumPy variant of the `dist_matrix` function from the Euclidian distance matrix example. How does the runtime compare with respect to the original variant? How about when using `fastmath=True` option?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-12T10:26:12.146005Z",
     "iopub.status.busy": "2020-11-12T10:26:12.141867Z",
     "iopub.status.idle": "2020-11-12T10:26:12.353431Z",
     "shell.execute_reply": "2020-11-12T10:26:12.308940Z",
     "shell.execute_reply.started": "2020-11-12T10:26:12.145936Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Hint: not all NumPy features are supported, e.g. `numpy.einsum` is not supported, or you need to use `expand_dims` or `reshape` instead of indexing/slicing with `None`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load ../examples/euclidean_distance_numpy.py\n",
    "#!/usr/bin/env Python3\n",
    "\"\"\"Euclidean distance example in 3 dimensional space\"\"\"\n",
    "\n",
    "import numpy\n",
    "\n",
    "def setup_points(n):\n",
    "    return numpy.indices((n, n, n), dtype=float).reshape((3, -1)).T\n",
    "\n",
    "def dist_matrix(points):\n",
    "    # To avoid computing the same multiple times, use:\n",
    "    # <x-y, x-y> = <x,x> -2 <x,y> + <y,y>\n",
    "    # The following is a more efficient way of writing (points**2).sum(axis=1):\n",
    "    p_2 = numpy.einsum(\"ij,ij->i\", points, points)\n",
    "    x_2 = p_2[:, None]\n",
    "    y_2 = p_2[None, :]\n",
    "    x_y = points @ points.T  # @ is matrix multiplication\n",
    "    return x_2 - 2 * x_y + y_2\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    M = dist_matrix(setup_points(10))\n",
    "    print(M[:5, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "* How to use pypy (ðŸš€) instead of CPython (ðŸŒ) if this is possible\n",
    "* Use the `@numba.njit` decorator to just-in-time-compile python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**And Now For Something Completely Different**\n",
    "\n",
    "<table>\n",
    "    <tr><td><img src=\"images/and-now-for-something-completely-different-2.jpg\" width=\"500px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://madmovieman.com/wp-content/uploads/2013/04/And-Now-For-Something-Completely-Different.jpg\">madmovieman.com</a></sub></center></td></tr>\n",
    "</table>\n",
    "\n",
    "<blockquote>\n",
    "In mathematics, a Borwein integral is an integral whose unusual properties were first presented by mathematicians David Borwein and Jonathan Borwein in 2001. These integrals are remarkable for exhibiting apparent patterns that eventually break down. The following is an example:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\int_0^\\infty \\frac{\\sin(x)}{x} dx = \\frac{\\pi}{2}\n",
    "$$\n",
    "$$\n",
    "\\int_0^\\infty \\frac{\\sin(x)}{x} \\frac{\\sin(x/3)}{x/3} dx = \\frac{\\pi}{2}\n",
    "$$\n",
    "$$\n",
    "\\int_0^\\infty \\frac{\\sin(x)}{x} \\frac{\\sin(x/3)}{x/3} \\frac{\\sin(x/5)}{x/5}dx = \\frac{\\pi}{2}\n",
    "$$\n",
    "This pattern continues up to\n",
    "$$\n",
    "\\int_0^\\infty \\frac{\\sin(x)}{x} \\frac{\\sin(x/3)}{x/3} \\cdots \\frac{\\sin(x/13)}{x/13}dx = \\frac{\\pi}{2}.\n",
    "$$\n",
    "At the next step the obvious pattern fails,\n",
    "$$\n",
    "\\int_0^\\infty \\frac{\\sin(x)}{x} \\frac{\\sin(x/3)}{x/3} \\cdots \\frac{\\sin(x/15)}{x/15}dx = \\frac{467807924713440738696537864469}{935615849440640907310521750000}\\pi\n",
    "$$\n",
    "$$\n",
    "= \\frac{\\pi}{2} - \\frac{6879714958723010531}{935615849440640907310521750000}\n",
    "\\approx \\frac{\\pi}{2} - 2.31 \\times 10^{-11}.\n",
    "$$\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "Source: [pythoninsider: Python 3.9.1 announcement](https://blog.python.org/2020/12/python-391-is-now-available-together.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# AOT: ahead-of-time compilation\n",
    "\n",
    "<dl>\n",
    "    <dt><strong>Ahead-Of-Time (AOT) compilation</strong></dt>\n",
    "    <dd>Compilation in languages, like C/C++, is done <em>before the program is run at all</em>. The bigger the source code to be compiled the longer it takes to compile it.</dd>\n",
    "</dl>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Pythran\n",
    "\n",
    "[Pythran](https://github.com/serge-sans-paille/pythran) is a *low-hanging fruit* AOT C++ compiler for Python, designed for scientific Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In particular Pythran has **no** support for:\n",
    "\n",
    "* classes (or object-oriented programming techniques in general),\n",
    "* containers (`list`, `dict`, ...) with inhomogeneous element types (except for tuples),\n",
    "* non-overflowing `int`s (only numbers that fit 64 bit integers; `int64_t`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Also Pythran uses deep copies, except for `numpy.ndarray`.\n",
    "E.g. when you modify a list argument within a function, the caller of the function will not see the changes.\n",
    "\n",
    "cf. [Pythran disclaimer](https://pythran.readthedocs.io/en/latest/MANUAL.html#disclaimer) and [Pythran limitations](https://pythran.readthedocs.io/en/latest/MANUAL.html#limitations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We will use Pythran IPython cell magic extension to run AOT compilation of the code in the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pythran\n",
    "\n",
    "%load_ext pythran.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Pythran make use of type annotations of the function signatures; we add them to the code as comments:\n",
    "```python\n",
    "# pythran export function_name(arg1_type, arg2_type, ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pythran\n",
    "\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "# pythran export approx_pi_pythran(int)\n",
    "def approx_pi_pythran(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi(2_000_000)\n",
    "%timeit approx_pi_pythran(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Analogous to C++ compilers, you can also use Pythran compiler with options to:\n",
    "\n",
    "* optimize code (`-O`),\n",
    "* use your native CPU's microprocessor level *single instruction, multiple data* (SIMD) support ([XSIMD](https://github.com/xtensor-stack/xsimd)), or\n",
    "* seamlessly parallelize `for` loops (using OpenMP)\n",
    "\n",
    "Note: except the `-O3` flag in the following example, the flags `-DUSE_XSIMD` and `-fopenmp` work on Linux but not on Mac."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pythran -O3 -DUSE_XSIMD -fopenmp\n",
    "\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "# pythran export approx_pi_pythran_optimized(int)\n",
    "def approx_pi_pythran_optimized(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_pythran_optimized(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "BUT Pythran has also (partial) NumPy support, and, when it does work, it does work fast with NumPy code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "def approx_pi_numpy(n_attempts):\n",
    "    points = numpy.random.rand(n_attempts, 2)\n",
    "    n_hits = numpy.count_nonzero((points ** 2).sum(1) <= 1.0)\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_numpy(2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%pythran\n",
    "# %load ../examples/pi_numpy.py\n",
    "#!/usr/bin/env Python3\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "# pythran export approx_pi_numpy_pythran(int)\n",
    "def approx_pi_numpy_pythran(n_attempts):\n",
    "    points = numpy.random.rand(n_attempts, 2)\n",
    "    n_hits = numpy.count_nonzero((points ** 2).sum(1) <= 1.0)\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_numpy_pythran(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "* Use pythran to compile restricted Python code => ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Cython\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <a href=\"https://cython.readthedocs.io/en/latest/src/userguide/migrating_to_cy30.html\">This section will be outdated as soon as Cython 3.0 will be out.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    Another similar aproach, which does not extend the Python syntax is\n",
    "    <a href=\"https://github.com/python/mypy/tree/master/mypyc\">mypyc</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* Language extension to Python allowing compilation of Python code to binary Python extensions.\n",
    "* `cdef` keyword to add static type C-like declarations, so the code (`.pyx` file extension) can be translated to C first (`.c` file). \n",
    "* In a second step, the `.c` file is compiled using a C compiler like `gcc` to a `.so` (unix) or a `.pyd` (windows) shared library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Code of many low level languages can be compiled into such shared libraries (C, C++, Fortran, ...).\n",
    "The resulting shared library will be built with an entrypoint for the Python interpreter, and can directly be imported from pure Python code.\n",
    "\n",
    "`.pyx` files do not necessarily have to use Cython type annotations. Cython also compiles pure Python files. However the resulting extension will not as optimized as when using annotated code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Usecases:**\n",
    "* Optimization of Python code\n",
    "* Wrap C / C++ libs: https://github.com/eth-cscs/PythonHPC/tree/master/cython/wrapping_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We start with pure ðŸ code: the $\\pi$ example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "\n",
    "def approx_pi(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time approx_pi(2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Lets see what happens if we start turning this code into Cython code! In the following, we are going to use the **jupyter notebook** [extension](https://cython.readthedocs.io/en/latest/src/quickstart/build.html#jupyter).\n",
    "If you want to use Cython natively (i.e. outside of a notebook), one way is to let a `setup.py` script compile the code for you. See [here](https://cython.readthedocs.io/en/latest/src/quickstart/build.html#building-a-cython-module-using-setuptools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Another way (which only works if you are not using any C extensions) is to use `pyximport`.\n",
    "This is for building Cython modules during development without explicitly running `setup.py` after each change.\n",
    "E.g. if you have a `pi.pyx`, you could do\n",
    "\n",
    "```python\n",
    "import pyximport; pyximport.install()\n",
    "import pi\n",
    "...\n",
    "```\n",
    "\n",
    "For more details, see the [Cython docs](https://docs.cython.org/en/latest/src/userguide/source_files_and_compilation.html#pyximport)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi_cython(n_attempts):\n",
    "    n_hits = 0\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time approx_pi_cython(2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_cython(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Although it is an improvement, we did not fully take the advantage of Cython.\n",
    "To work with maximal performance, Cython needs to know the type of every variable (is the variable a `float` or is it an `int`). This is similar to NumPy (see Section 1.1.1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We add some type declarations and things will get better. **Type declarations** are defined by the `cdef` keyword (old style / not pure Python) or using types from the `cython` module, e.g. `cython.int` (modern style).\n",
    "We will first introduce the old style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    As types for the variables, we will use <code>long</code> here. The Python type <code>int</code> is implemented by a <code>long</code> in C. If you would use a C <code>int</code>, you would get a integer overflow for integers greater than $2147483647 = 2^{31}$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi_cython_v2(n_attempts):\n",
    "    cdef long n_hits = 0 # added type\n",
    "    cdef double x, y # added types\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%time approx_pi_cython_v2(2_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_cython_v2(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "So we gained almost a factor of 1.5 by adding some type declarations.\n",
    "\n",
    "Can we improve speed further?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "If you add `--annotate` or `-a` to view the generated C code, yellow lines will mark parts of the code which could not be converted to pure C code and require fall back to interpreted Python.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    By minimizing the yellow part, you maximize Cython's performance!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "In the following example Cython cannot figure out a types for `n`, and `i`. Therefore it uses a generic CPython type, all lines performing operations involving those variables will be marked yellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi_cython_v2(n_attempts):\n",
    "    cdef long n_hits = 0\n",
    "    cdef double x, y\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Note: you can also click on the lines to see the generated `C` code!\n",
    "\n",
    "You can see that the code behind the yellow lines involving the Python interpreter (e.g. line 9) looks very complicated, whereas the other code, e.g. line 12, looks much simpler, although the original variable names are mangled into `C` variable names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Lets try to get rid of the yellow line containing the for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "def approx_pi_cython_v3(long n_attempts): # added type\n",
    "    cdef long n_hits = 0\n",
    "    cdef double x, y\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = uniform(-1.0, 1.0)\n",
    "        y = uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Thats all we can do by just adding type hints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "* The yellow line at `import` does not matter, it is only called once.\n",
    "* We cannot improve the lines at `def` and `return`. By removing the Python interaction at `def` and `return`, the function becomes inaccessable from pure Python code. The interactions are responsible for converting data to and from `C`.\n",
    "* We also cannot remove the Python interaction originating from the `uniform` call, as this is a pure Python function. This line is in fact the real bottle neck of the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%timeit approx_pi_cython_v3(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To optimize further, we have to replace the Python random generator by a C equivalent.\n",
    "\n",
    "A low level function which only takes C variables as input and only returns C variables (cannot be used in pure python code), can be declared by using `cdef` followed by the C return type instead of `def`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "cimport cython\n",
    "\n",
    "cdef extern from \"stdlib.h\":\n",
    "    double drand48()\n",
    "    void srand48(long int seedval)\n",
    "cdef extern from \"time.h\":\n",
    "    long int time(int)\n",
    "cdef double c_uniform(double x0, double x1):\n",
    "    return x0 + drand48() * (x1 - x0)\n",
    "srand48(time(0)) # Initialize random number generator\n",
    "\n",
    "def approx_pi_cython_v4(long n_attempts):\n",
    "    cdef long n_hits = 0\n",
    "    cdef double x, y\n",
    "\n",
    "    for _ in range(n_attempts):\n",
    "        x = c_uniform(-1.0, 1.0)\n",
    "        y = c_uniform(-1.0, 1.0)\n",
    "        if x ** 2 + y ** 2 <= 1.0:\n",
    "            n_hits += 1\n",
    "    return 4 * n_hits / n_attempts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this [appendix](./appendix.ipynb) you can read more on low level C functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Pure ðŸ\")\n",
    "%time approx_pi(2_000_000)\n",
    "print(\"Cython - untyped\")\n",
    "%time approx_pi_cython(2_000_000)\n",
    "print(\"Cython - partially typed\")\n",
    "%time approx_pi_cython_v2(2_000_000)\n",
    "print(\"Cython - typed\")\n",
    "%time approx_pi_cython_v3(2_000_000)\n",
    "print(\"Cython - Fully optimized\")\n",
    "%time approx_pi_cython_v4(2_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "ðŸš€ So we are now faster by a factor of about ~120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "If you manage to get rid of all Python interaction, you even can expect speedup by a factor up to ~100 depending on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Using Python type hints\n",
    "Instead of using `cdef` we can use Python type hints. However, if we would just use pure Python types hints (e.g. `int`), Cython would ignore them. The reason is that Python only offers `int` as an integer type, where in C/Cython there are more than just one integer type (e.g. `short`, `int`, `long`). Instead, we have to use Cython counterparts (i.e. `cython.int`, `cython.long` instead of `int`).\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "     âš  Types as <code>int</code>, <code>double</code>, ... are actually defined in both modules <code>cython</code> and <code>Cython</code>. Only types from <code>cython</code> (lower case) will work!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import cython\n",
    "\n",
    "def approx_pi_lattice_cython_v3(delta: cython.double):  # Changed type hint\n",
    "    n_hits: cython.long = 0 # Changed type hint\n",
    "    x: cython.double # Changed type hint\n",
    "    y: cython.double # Changed type hint\n",
    "    x = -1.\n",
    "    while x <= 1.:\n",
    "        y = -1.\n",
    "        while y <= 1.:\n",
    "            if x ** 2 + y ** 2 <= 1.0:\n",
    "                n_hits += 1\n",
    "            y += delta\n",
    "        x += delta\n",
    "    return 4 * n_hits * delta**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Exercise (20 min)\n",
    "\n",
    "The following version of the $\\pi$ example,\n",
    "we dont use a random generator, but cover the square by a lattice instead.\n",
    "\n",
    "Rewrite this version using Cython!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def approx_pi(resolution):\n",
    "    \"\"\"\n",
    "    :param resolution: number of grid -1 points in 1 dimension\n",
    "    \"\"\"\n",
    "    n_hits = 0\n",
    "    for i in range(resolution):\n",
    "        for j in range(resolution):\n",
    "            x = 2 * i / resolution - 1\n",
    "            y = 2 * j / resolution - 1\n",
    "            if x ** 2 + y ** 2 <= 1.0:\n",
    "                n_hits += 1\n",
    "    return 4 * n_hits / resolution ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "**Step 1**: Just use type annotations (prefer pure Python type hints, e.g. `cython.int` over `cdef`) to reduce the yellow lines.\n",
    "\n",
    "Why are the lines `x = 2*i/resolution - 1` and `y = 2*i/resolution - 1` still yellow?\n",
    "\n",
    "Hint: If you cant figure it out, [look here](./exercise_hints.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Step 2**: Get rid of the Python interaction at the two yellow lines mentioned in step 1. If you dont know how, read the hint in step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Auto infer types inside functions\n",
    "When working with functions, instead of explicitly give type annotations, Cython also can **automatically infer types** via a decorator `@infer_types`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "import cython\n",
    "\n",
    "@cython.infer_types\n",
    "def approx_pi_lattice_cython_v4(delta: cython.double):  # Still have to give a type hint here\n",
    "    n_hits = 0 # automatically inferred\n",
    "    x = -1. # automatically inferred\n",
    "    while x <= 1.:\n",
    "        y = -1. # automatically inferred\n",
    "        while y <= 1.:\n",
    "            if x ** 2 + y ** 2 <= 1.0:\n",
    "                n_hits += 1\n",
    "            y += delta\n",
    "        x += delta\n",
    "    return 4 * n_hits * delta**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Note, that we still have to declare the type of the argument `delta` in the function declaration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## numpy support\n",
    "Cython can handle NumPy data types out of the box:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "import numpy\n",
    "\n",
    "def sum_array(double[:] x):\n",
    "    cdef int i, nx = x.shape[0]\n",
    "    cdef double s = 0.0\n",
    "    for i in range(nx):\n",
    "        s += x[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "The notation `double[:]` is inspired by numpy.\n",
    "Here, it declares a 1-dim array. You would use `double[:, :]` to declare a 2-dim array, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "For safety reasons, Cython checks if we try to access elements out of the array boundaries. Furthermore it allows using negative array indices and translates them to positive indices (counting back from the end).\n",
    "Both **safety features may be disabled to improve performance**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "from cython cimport boundscheck, wraparound\n",
    "\n",
    "\n",
    "@wraparound(False)\n",
    "@boundscheck(False)\n",
    "def sum_array(double[:] x):\n",
    "    cdef int i, nx = x.shape[0]\n",
    "    cdef double s = 0.0\n",
    "    for i in range(nx):\n",
    "        s += x[i]\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Parallelization with OpenMP\n",
    "\n",
    "MP abbreviates *Multi Processing*. It is an API for multi-platform shared-memory multiprocessing programming on one machine.\n",
    "Cython can make use of OpenMP.\n",
    "\n",
    "In the following cell, we are injecting the compiler args `-fopenmp` via distutils (distutils is used behind the scenes to start the compiler) to compile and link the block with the OpenMP C library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "\n",
    "# distutils: extra_compile_args = -fopenmp -march=native\n",
    "# distutils: extra_link_args = -fopenmp\n",
    "# cimport numpy  # special compile-time information about the numpy module\n",
    "from cython cimport boundscheck, wraparound\n",
    "from cython.parallel cimport prange\n",
    "\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "def parallel_sum(double[:, :] x, double[:] out):\n",
    "    cdef int i, j, m = x.shape[0], n = x.shape[1]\n",
    "    for i in prange(m, nogil=True):\n",
    "        for j in range(n):\n",
    "            out[i] += x[i, j]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## Advanced features\n",
    "Have a look at the [Cython tutorials](https://cython.readthedocs.io/en/latest/src/tutorial/index.html).\n",
    "E.g.\n",
    "* [C-like Allocation/Dealllocation](https://cython.readthedocs.io/en/latest/src/tutorial/memory_allocation.html)\n",
    "* [Extension Types](https://cython.readthedocs.io/en/latest/src/tutorial/cdef_classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Packaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Good practice</b>: <a href=\"https://cython.readthedocs.io/en/latest/src/userguide/source_files_and_compilation.html#distributing-cython-modules\">Distribute the generated .c files alongside the Cython sources</a>, so that users are not required to have Cython available.\n",
    "    <p>Also Cython compilation should be disabled by default during setup.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    },
    "tags": []
   },
   "source": [
    "Even if the end user has Cython installed, he/she probably doesnâ€™t want to use it just to install the module.\n",
    "Also, the installed Cython version may differ from the Cython version used to package, and may not compile your sources correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "An example of a folder structure for the `euclidean_distance` package would be\n",
    "\n",
    "```\n",
    "euclidean_distance\n",
    "â”œâ”€â”€ euclidean_distance.pyx\n",
    "â”œâ”€â”€ euclidean_distance.c\n",
    "â”œâ”€â”€ pyproject.toml\n",
    "â”œâ”€â”€ README.md\n",
    "â””â”€â”€ setup.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`euclidean_distance.pyx`: Cython code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "`README.md`: Description / docs about your package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "`euclidean_distance.c`: Generated by Cython, enclosed to the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`pyproject.toml` declares the build environment (without it `pip install` would not know which build system to use to install the package)\n",
    "\n",
    "```toml\n",
    "[build-system]\n",
    "requires = [\"setuptools\", \"wheel\"]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "```\n",
    "\n",
    "â„¹ If you dont include the `.c` file, also `cython` would be required, and you would have to add `\"Cython\"` to `requires`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "`setup.py`: Compile recipy.\n",
    "\n",
    "Could look like:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env Python3\n",
    "\n",
    "from numpy import get_include as _numpy_get_include\n",
    "from setuptools import setup, Extension\n",
    "\n",
    "try:\n",
    "  from Cython.Build import Cythonize\n",
    "  USE_CYTHON = True\n",
    "except ImportError:\n",
    "  USE_CYTHON = False\n",
    "\n",
    "ext = '.pyx' if USE_CYTHON else '.c'\n",
    "extensions = [Extension(\n",
    "  \"euclidean_distance\",\n",
    "  sources=[\"euclidean_distance\" + ext],\n",
    "  include_dirs=[_numpy_get_include()])]\n",
    "\n",
    "if USE_CYTHON:\n",
    "  extensions = Cythonize(extensions)\n",
    "\n",
    "setup(\n",
    "  name='euclidean_distance',\n",
    "  ext_modules=extensions,\n",
    "  zip_safe=False,\n",
    "  install_requires=[\"numpy\"]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "With this package structure, you can build the package for direct usage in the current project folder, using\n",
    "\n",
    "```bash\n",
    "python setup.py build_ext --inplace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "To distribute it (both binary and source versions) to pypi, you would use\n",
    "\n",
    "```bash\n",
    "python setup.py sdist bdist_wheel\n",
    "twine upload --repository-url $PYPI_REPOSITORY_URL dist/*\n",
    "```\n",
    "\n",
    "Where you have to specify the url to your pypi project. For more details, see [here](https://twine.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* How to modify pure Python code (ðŸŒ) to Cython code (ðŸš€)\n",
    "* Compile Cython code to a Python C extension\n",
    "* Packaging to a Python extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr><td><img src=\"images/and-now-for-something-completely-different-3.jpg\" width=\"500px\"></td></tr>\n",
    "    <tr><td><center><sub>Source: <a href=\"https://www.themoviedb.org/movie/9267-and-now-for-something-completely-different/images/posters?image_language=en\">www.themoviedb.org</a></sub></center></td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Using other compiled languages\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    â„¹ When developing extensions written in compiled languages, you will need to install a compiler for that language.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Fortran: F2PY (part of numpy)\n",
    "WTF is Fortran?\n",
    "\n",
    "![Fortran](./images/hpc-joke.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<small>Fortran (Formula Translation) is a compiled imperative programming language designed for numeric computation and scientific computing. In the number crunching scene, [it recently again gained popularity](https://www.zdnet.com/article/this-old-programming-language-is-suddenly-getting-more-popular-again/).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <a href=\"https://numpy.org/doc/stable/f2py/index.html\">F2py</a> comes bundled with numpy (<code>pip install numpy</code>).\n",
    "    Fortran code that works fine with F2py is very easy to integrate!\n",
    "</div>\n",
    "\n",
    "F2py turns Fortran code into a Python extension.\n",
    "\n",
    "It uses numpy_distutils that supports a number of Fortran 77/90/95 compilers, including GNU, Intel, Sun Fortre, SGI MIPSpro, Absoft, NAG, Compaq etc. compilers.\n",
    "For more details, see [here](https://numpy.org/doc/stable/f2py/f2py.getting-started.html#three-ways-to-wrap-getting-started).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Here is the Monte Carlo $\\pi$ example in Fortran:\n",
    "\n",
    "`pi.f`:\n",
    "```Fortran\n",
    "      SUBROUTINE APPROX_PI(N_ATTEMPTS, OUT)\n",
    "C\n",
    "C     MONTE CARLO COMPUTATION TO APPROXIMATE PI\n",
    "C     \n",
    "      INTEGER N_ATTEMPTS\n",
    "      REAL*8 OUT\n",
    "      REAL*8 X, Y\n",
    "Cf2py intend(in) n_attempts\n",
    "Cf2py intent(out) out\n",
    "      INTEGER N_HITS\n",
    "\n",
    "      N_HITS = 0\n",
    "      \n",
    "      CALL SRAND(86456)\n",
    "\n",
    "      DO I=1,N_ATTEMPTS\n",
    "         X = 2.0D0 * RAND() - 1.0D0\n",
    "         Y = 2.0D0 * RAND() - 1.0D0\n",
    "         IF (X*X + Y*Y <= 1.0D0) THEN\n",
    "            N_HITS = N_HITS + 1\n",
    "         ENDIF\n",
    "      ENDDO\n",
    "      OUT = 4.0D0 * N_HITS / N_ATTEMPTS\n",
    "      END\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To build a Python extension, just use\n",
    "```bash\n",
    "python -m numpy.f2py -c -m pi pi.f\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Then use it in a Python ðŸ file:\n",
    "```python\n",
    "from pi import approx_pi\n",
    "\n",
    "print(approx_pi(2_000_000))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To deal with numpy arrays, you have to make sure, that input arrays are Fortran-contiguous, i.e. matrix data is transposed in memory compared to the C version (see the [docs](https://numpy.org/doc/stable/f2py/f2py.getting-started.html#the-quick-way))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## C/C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [ctypes](https://docs.python.org/3/library/ctypes.html)\n",
    "\n",
    "Foreign function library\n",
    "\n",
    "* part of the Python Standard Library\n",
    "* Provides C compatible data types\n",
    "* Allows loading and calling functions in existing shared libraries (see [cython introduction](#Cython))\n",
    "* Can be used to wrap libraries in pure Python\n",
    "* No need for compilation, if shared C library already is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Monte Carlo $\\pi$ example in C:\n",
    "\n",
    "`approx_pi.c`:\n",
    "```C\n",
    "#include <stdlib.h>\n",
    "\n",
    "#include \"approx_pi.h\"\n",
    "\n",
    "double approx_pi(unsigned int n_attempts) {\n",
    "  /* C core function   */\n",
    "  unsigned int n_hits = 0, i;\n",
    "  double x, y;\n",
    "  for(i=0; i<n_attempts; i++) {\n",
    "    x = 2.*rand()/RAND_MAX -1.;\n",
    "    y = 2.*rand()/RAND_MAX -1.;\n",
    "    if(x*x + y*y <= 1.0) n_hits ++;\n",
    "  }\n",
    "  return 4. * n_hits / n_attempts;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Compile it with `gcc -shared approx_pi.c -o approx_pi.so`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Use it in ðŸ:\n",
    "```python\n",
    "from ctypes import cdll, c_double\n",
    "\n",
    "approx_pi = cdll.LoadLibrary(\"./approx_pi.so\").approx_pi\n",
    "approx_pi.restype = c_double  # By default ctypes assumes int as a return type\n",
    "\n",
    "pi = approx_pi(2_000_000)\n",
    "print(pi, type(pi))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [pybind11](https://pybind11.readthedocs.io/en/stable/), [boost Python](https://www.boost.org/doc/libs/1_79_0/libs/python/doc/html/index.html), [nanobind](https://github.com/wjakob/nanobind)\n",
    "\n",
    "* Useful for big projects\n",
    "* You can even map C++ classes to Python classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Monte Carlo $\\pi$ example in pybind11 (C++):\n",
    "\n",
    "`pi.cpp`:\n",
    "```cpp\n",
    "#include <random>\n",
    "#include <pybind11/pybind11.h>\n",
    "\n",
    "double approx_pi(unsigned int n_attempts) {\n",
    "  std::random_device generator;\n",
    "  std::uniform_real_distribution<double> distribution(-1.0,1.0);\n",
    "  \n",
    "  unsigned int n_hits = 0;\n",
    "  double x, y;\n",
    "  for(unsigned int i=0; i<n_attempts; i++) {\n",
    "    x = distribution(generator);\n",
    "    y = distribution(generator);\n",
    "    if(x*x + y*y <= 1.0) n_hits ++;\n",
    "  }\n",
    "  return 4. * n_hits / n_attempts;\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(pi, m) {\n",
    "    m.doc() = \"Pi\"; // optional module docstring\n",
    "\n",
    "    m.def(\"approx_pi\", &approx_pi, \"Approximates pi\");\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Compile it with\n",
    "```bash\n",
    "c++ -O3 -Wall -shared -std=c++11 -fPIC `python3 -m pybind11 --includes` pi.cpp -o pi`python3-config --extension-suffix`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Use it in ðŸ:\n",
    "```python\n",
    "from pi import approx_pi\n",
    "\n",
    "print(approx_pi(2_000_000))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### [SWIG](http://swig.org/)\n",
    "\n",
    "â„¹ SWIG also can be used for other programming languages than C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Monte Carlo $\\pi$ example: Take `approx_pi.c` from Subsection *ctypes*.\n",
    "Add a file `pi_swig.i`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "```c\n",
    "%module pi_swig\n",
    "\n",
    "%{\n",
    "#define SWIG_FILE_WITH_INIT\n",
    "#include \"approx_pi.h\"\n",
    "%}\n",
    "\n",
    "double approx_pi(unsigned int n_attempts);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Then let swig autogenerate C code to wrap `approx_pi.c` into a C extension, using Pythons C-API:\n",
    "```bash\n",
    "swig -python pi_swig.i\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Write a `setup.py`:\n",
    "\n",
    "```python\n",
    "#!/usr/bin/env Python3\n",
    "\"\"\"\n",
    "To only compile the C extension inplace:\n",
    "python setup.py build_ext --inplace\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    from setuptools import setup, find_packages, Extension\n",
    "except ImportError:\n",
    "    raise RuntimeError('setuptools is required')\n",
    "\n",
    "setup(name=\"pi_swig\",\n",
    "      version=\"1.0\",\n",
    "      packages=find_packages(),\n",
    "      package_dir={\"pi_swig\": \".\"},\n",
    "      description=\"Pi\",\n",
    "      Python_requires=\">=3.5\",\n",
    "      ext_modules=[Extension(\n",
    "          '_pi_swig',\n",
    "          sources=[\"approx_pi.c\", \"pi_swig_wrap.c\"])]\n",
    "      )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Compile it with `setup.py build_ext --inplace`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Use it in ðŸ:\n",
    "```python\n",
    "from pi_swig import approx_pi\n",
    "\n",
    "print(approx_pi(2_000_000))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## [Rust](https://www.rust-lang.org/)\n",
    "\n",
    "* Main focus: memory / thread safety without the need of a garbage collector\n",
    "* Near C performance\n",
    "* High level abstractions like C++\n",
    "* Low boilerplate ðŸ extensions with the [PyO3](https://pyo3.rs) crate (Rust package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "As Rust (Abbreviated by ðŸ¦€ because of Rust's mascot, Ferris the Crab) is heavily based on its own ecosystem (cargo as build system / dependency manager), the developpers created an own ðŸ packager [Maturin](https://github.com/PyO3/maturin) (also available on pypi) which can replace setuptools for ðŸ¦€ extensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Monte Carlo $\\pi$ example in ðŸ¦€:\n",
    "\n",
    "`src/lib.rs`\n",
    "```rust\n",
    "use pyo3::prelude::{pymodule, PyModule, PyResult, Python};\n",
    "use rand;\n",
    "\n",
    "#[pymodule]\n",
    "fn pi(_py: Python, m: &PyModule) -> PyResult<()> {\n",
    "    #[pyfn(m, \"approx_pi\")]\n",
    "    fn approx_pi<'a>(_py: Python, n_attempts: u32) -> PyResult<f64> {\n",
    "        let mut n_hits: u32 = 0;\n",
    "        for _ in 0..n_attempts {\n",
    "            let x = 2. * rand::random::<f64>() - 1.;\n",
    "            let y = 2. * rand::random::<f64>() - 1.;\n",
    "            if x * x + y * y <= 1.0 {\n",
    "                n_hits += 1;\n",
    "            }\n",
    "        }\n",
    "        Ok(4. * n_hits as f64 / n_attempts as f64)\n",
    "    }\n",
    "    Ok(())\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To build it with cargo, you also need a `Cargo.toml` file:\n",
    "```toml\n",
    "[package]\n",
    "name = \"pi\"\n",
    "version = \"0.1.0\"\n",
    "authors = [\"Chuck Norris <chucknorris@roundhouse.gov>\"]\n",
    "edition = \"2021\"\n",
    "\n",
    "[lib]\n",
    "name = \"pi\"\n",
    "crate-type = [\"cdylib\"]\n",
    "\n",
    "[dependencies]\n",
    "pyo3 = {version = \"0.12\", features = [\"extension-module\"]}\n",
    "rand = \"0.7\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Build it with `cargo build --release`  (here, we are not using maturin). Copy the resulting `target/release/libpi.so` as `pi.so` into either your `$PYTHON_PATH` or into the directory, your ðŸ importing this extension resides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Use it in ðŸ:\n",
    "```python\n",
    "from pi import approx_pi\n",
    "\n",
    "print(approx_pi(2_000_000))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Basics on how to use foreign languages (ðŸš€) in python (ðŸŒ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HPC techniques: When to use what?\n",
    "In general: stick with numpy as long as you can, occasionally bringing in Numba!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "* Sometimes there is an existing library written in Fortran / C you want to wrap -> use Cython / f2py / pyO3 / ...\n",
    "* Sometimes there is a usecase not covered by NumPy / SciPy. Numba not fast enough or you also want to have interfaces to another language -> Use a foreign language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "|  |  |  |  |\n",
    "|--|--|--|--|\n",
    "| ![](images/logos/py-flat.svg) | Pure Python | easy but ðŸŒ |\n",
    "| ![](images/logos/numpy.svg) | numpy | Easy to use but restricted, good algorithms out of the box. Use as long as you can! |\n",
    "| ![](images/logos/numba.svg) | numba | Less restricted than numpy, some care to distinguish between code that can be handled by Numba (not everything supported), array processing |\n",
    "| | Pythran | Works on restricted Python only |\n",
    "| ![](images/logos/cython.svg) | Cython | <table>    <tr><td>-</td><td>Need to learn new Cython syntax</td></tr>    <tr><td>-</td><td>More work to setup for the compilation / setup.py, code preparation</td></tr>    <tr><td>+</td><td>Flexibility (even more than NumPy / Numba)</td></tr>    <tr><td>-</td><td>C Pitfalls (SEG Fault)</td></tr>    <tr><td>+</td><td>Use C libraries in Python</td></tr>    <tr><td>-</td><td>Problematic on Windows because of not standard windows C compiler, WSL</td></tr>    <tr><td>-</td><td>Not pure Python (e.g. <code>cdef</code> keyword) -> lock in (will hopefully change soon in Cython 3.0)</td></tr></table> |\n",
    "| ![](images/logos/C.svg) ![](images/logos/fortran.svg) ![](images/logos/rust.svg) | Foreign Languages | <table><tr><td>-</td><td>Need to know that language</td></tr><tr><td>-</td><td>need a compiler / adds overhead in the distribution phase</td></tr><tr><td>+</td><td>maximal flexibility / ðŸš€</td></tr></table> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "â„¹ Cython and foreign languages require compilers to be installed. This adds a layer of difficulty, because e.g. this is not the case on Windows by default (but currently there is a free installer from MS to get a compiler). Therefore in this case, it is good practice to build and distribute binary wheels in addition to source packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "* [Python as glue](https://numpy.org/doc/1.18/user/c-info.python-as-glue.html)\n",
    "* [numexpr](https://numexpr.readthedocs.io/en/latest/)\n",
    "* [PyPy](https://www.pypy.org/)\n",
    "* [Numba](https://numba.pydata.org/)\n",
    "* [Pythran](https://github.com/serge-sans-paille/pythran)\n",
    "* [Cython](https://cython.org/)\n",
    "* [F2PY](https://numpy.org/doc/stable/f2py/index.html)\n",
    "* [ctypes](https://docs.python.org/3/library/ctypes.html)\n",
    "* [pybind11](https://pybind11.readthedocs.io/en/stable/)\n",
    "* [Swig](http://swig.org/)\n",
    "* [PyO3](https://pyo3.rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "rise": {
   "scroll": true,
   "transition": null
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
